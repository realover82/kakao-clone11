
import streamlit as st
import pandas as pd
import numpy as np
import sqlite3
import os
import io
import re
from datetime import datetime, timedelta

# ==============================================================================
# 0. ì „ì—­ ì„¤ì • ë° í•¨ìˆ˜ ì •ì˜
# ==============================================================================

# ğŸ’¡ DB íŒŒì¼ëª…ì„ í˜„ì¬ ì‹¤í–‰ ë””ë ‰í† ë¦¬ì— ì €ì¥í•˜ë„ë¡ ì„¤ì •
DB_FILE = r'./db/product_history_d2.db' 
BASE_MEASUREMENTS = [
    'PcbSleepCurr', 'PcbBatVolt', 'PcbIrCurr', 'PcbIrPwr', 'PcbWirelessVolt',
    'PcbUsbCurr', 'PcbWirelessUsbVolt', 'PcbLed'
]

# ------------------------------------------------------------------------------
# 0-1. ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# ------------------------------------------------------------------------------
@st.cache_resource
def get_db_connection(db_name):
    """ SQLite ì—°ê²°ì„ ìºì‹œí•˜ì—¬ ì•ˆì •ì ì¸ ì„¸ì…˜ì„ ìœ ì§€í•©ë‹ˆë‹¤. """
    conn = sqlite3.connect(db_name, check_same_thread=False)
    return conn

def get_table_names(conn):
    """ DBì— ì¡´ì¬í•˜ëŠ” ëª¨ë“  í…Œì´ë¸” ì´ë¦„ì„ ê°€ì ¸ì˜µë‹ˆë‹¤. """
    query = "SELECT name FROM sqlite_master WHERE type='table' AND name NOT LIKE 'sqlite_%';"
    df_tables = pd.read_sql_query(query, conn)
    return df_tables['name'].tolist()

@st.cache_data
def clean_excel_string(series):
    """ Excel í˜•ì‹ì˜ ="..." ë¬¸ìì—´ ë° ì•ë’¤ ê³µë°±ì„ ì œê±°í•©ë‹ˆë‹¤. """
    series = series.astype(str).str.replace(r'="', '', regex=True).str.replace(r'"', '', regex=True).replace('nan', np.nan)
    if series.dtype == 'object': 
        series = series.str.strip()
    return series

def get_total_count_for_query(conn, sql_query):
    """ í˜„ì¬ ì¿¼ë¦¬ì—ì„œ LIMITì„ ì œê±°í•˜ê³  ì´ í–‰ ê°œìˆ˜ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤. """
    try:
        import re
        cleaned_query = re.sub(r'LIMIT\s+\d+\s*;?\s*$', '', sql_query.strip(), flags=re.IGNORECASE).rstrip('; ')
        
        if not cleaned_query.lower().startswith('select') and not cleaned_query.lower().startswith('with'):
             return None, "ìœ íš¨í•˜ì§€ ì•Šì€ ì¿¼ë¦¬"
             
        # ì „ì²´ë¥¼ ì„œë¸Œì¿¼ë¦¬ë¡œ ê°ì‹¸ì„œ COUNT(*) ì‹¤í–‰
        count_query = f"SELECT COUNT(*) FROM ({cleaned_query})"
        
        df_count = pd.read_sql_query(count_query, conn)
        total_count = df_count.iloc[0, 0]
        return total_count, None
    except Exception as e:
        return None, str(e)
    
# ------------------------------------------------------------------------------
# (ì¶”ê°€) ë‚ ì§œ ê¸°ë³¸ê°’ ê³„ì‚° ìœ í‹¸ë¦¬í‹°
# ------------------------------------------------------------------------------
@st.cache_data
def get_default_dates():
    """ ë‚ ì§œ ê³„ì‚° ê²°ê³¼ë¥¼ ëª…ì‹œì ìœ¼ë¡œ ìºì‹œí•©ë‹ˆë‹¤. """
    today = datetime.now().date()
    # 30ì¼ ì „ ë‚ ì§œ ê³„ì‚°
    default_start = today - timedelta(days=1) 
    return today, default_start


# ------------------------------------------------------------------------------
# 0-2. ë°ì´í„° ë¡œë“œ ë° ì €ì¥ í•¨ìˆ˜
# ------------------------------------------------------------------------------
@st.cache_data(show_spinner="CSV íŒŒì¼ ë¶„ì„ ë° ì „ì²˜ë¦¬ ì¤‘...")
def load_data_with_dynamic_header(uploaded_file, test_week):
    """ ë™ì  í—¤ë” íƒìƒ‰ ë° ë°ì´í„° ì „ì²˜ë¦¬ í›„ DataFrame ë°˜í™˜ (ì›ë³¸ ë¡œì§ ì¬í˜„) """
    try:
        file_content = uploaded_file.getvalue()
        file_io = io.StringIO(file_content.decode('utf-8'))
        df = pd.read_csv(file_io, header=4) 
        
        # --- ì „ì²˜ë¦¬ ë¡œì§ ---
        df.columns = [str(col).strip() for col in df.columns] 
        object_cols_to_clean = ['SNumber', 'PcbSleepCurr', 'PcbMaxSleepCurr', 'PcbMinSleepCurr', 'PcbBatVolt', 'PcbMaxBatVolt', 'PcbMinBatVolt', 'PcbIrCurr', 'PcbMaxIrCurr', 'PcbMinIrCurr', 'PcbIrPwr', 'PcbMaxIrPwr', 'PcbMinIrPwr', 'PcbWirelessVolt', 'PcbMaxWirelessVolt', 'PcbMinWirelessVolt', 'PcbUsbCurr', 'PcbMaxUsbCurr', 'PcbMinUsbCurr', 'PcbWirelessUsbVolt', 'PcbMaxWirelessUsbVolt', 'PcbMinWirelessUsbVolt', 'PcbLed', 'PcbMaxLed', 'PcbMinLed', 'PcbPass']
        for col in object_cols_to_clean:
            if col in df.columns: df[col] = clean_excel_string(df[col])
        numeric_pcb_cols = [col for col in object_cols_to_clean if col not in ['SNumber', 'PcbPass']]
        for col in numeric_pcb_cols:
            df[col] = pd.to_numeric(df[col], errors='coerce')
        
        TIME_FORMAT_COMPACT = '%Y%m%d%H%M%S'
        df['PcbStartTime'] = pd.to_datetime(df['PcbStartTime'].astype(str).str.replace(r'="', '', regex=True).str.replace(r'"', '', regex=True).str.strip(), errors='coerce', format=TIME_FORMAT_COMPACT)
        df['PcbStopTime'] = pd.to_datetime(df['PcbStopTime'].astype(str).str.replace(r'="', '', regex=True).str.replace(r'"', '', regex=True).str.strip(), errors='coerce', format=TIME_FORMAT_COMPACT)
        df['Stamp'] = pd.to_datetime(df['Stamp'], errors='coerce', format='%Y-%m-%d %H:%M:%S', exact=False)

        # 3. DB í…Œì´ë¸”ìš© DataFrame ìƒì„±
        model_name = 'SJ_TM2360E'; model_suffix = 'PCB'
        df_product = df[['SNumber']].drop_duplicates().copy()
        df_product['ProductModel_Name'] = model_name; df_product['ProductModel_Suffix'] = model_suffix
            
        specs = [];
        for item in BASE_MEASUREMENTS:
            min_col = f'PcbMin{item[3:]}'; max_col = f'PcbMax{item[3:]}'
            if min_col in df.columns and max_col in df.columns:
                min_val = df[min_col].dropna().iloc[0] if not df[min_col].dropna().empty else np.nan
                max_val = df[max_col].dropna().iloc[0] if not df[max_col].dropna().empty else np.nan
                specs.append({'TestItemName': item, 'MinLimit': min_val, 'MaxLimit': max_val})
        df_spec = pd.DataFrame(specs)
        
        history_cols_base = ['Unnamed: 0', 'SNumber', 'Stamp', 'ICount', 'PcbStartTime', 'PcbStopTime', 'PcbPass']
        valid_history_cols = [col for col in history_cols_base if col in df.columns] + [col for col in BASE_MEASUREMENTS if col in df.columns]
        df_history = df[valid_history_cols].copy()
        
        if 'Unnamed: 0' in df_history.columns: df_history.rename(columns={'Unnamed: 0': 'Original_Local_TestID'}, inplace=True)
        df_history['TestWeek'] = test_week 
        column_mapping = {'Stamp': 'TestStamp'}
        for col in BASE_MEASUREMENTS: 
            if col in df_history.columns: column_mapping[col] = f'{col}_Value'
        df_history = df_history.rename(columns=column_mapping)
        df_history.dropna(axis=1, how='all', inplace=True)
        
        return df_product, df_spec, df_history

    except Exception as e:
        st.error(f"íŒŒì¼ ë¡œë“œ ë° ì „ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None, None, None


def save_dataframes_to_db(conn, df_product, df_spec, df_history):
    """ DataFrameë“¤ì„ DBì— ì¶”ê°€/ë®ì–´ì“°ê¸° í•©ë‹ˆë‹¤. """
    try:
        df_product.to_sql('PRODUCT', conn, if_exists='append', index=False)
        df_spec.to_sql('TEST_SPECIFICATION', conn, if_exists='replace', index=False)
        df_history.to_sql('TEST_HISTORY', conn, if_exists='append', index=True, index_label='History_PK')
        return True, len(df_history)
    except Exception as e:
        st.error(f"âŒ DB ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return False, 0

# ------------------------------------------------------------------------------
# 0-3. DB í˜„í™© ë° ì‚­ì œ í•¨ìˆ˜
# ------------------------------------------------------------------------------
def get_db_status(conn):
    """ DBì— ì €ì¥ëœ ì£¼ì°¨ë³„, ëª¨ë¸ë³„, ì—°ë„ë³„ ë°ì´í„° í˜„í™©ì„ ì¡°íšŒí•©ë‹ˆë‹¤. """
    query = """
    SELECT
        strftime('%Y', T1.TestStamp) AS Year,
        T1.TestWeek,
        T2.ProductModel_Suffix,
        COUNT(T1.History_PK) AS RecordCount,
        COUNT(DISTINCT T1.SNumber) AS UniqueProducts
    FROM TEST_HISTORY AS T1
    JOIN PRODUCT AS T2 ON T1.SNumber = T2.SNumber
    GROUP BY 1, 2, 3
    ORDER BY Year DESC, TestWeek DESC;
    """
    try:
        df_status = pd.read_sql_query(query, conn)
        return df_status
    except Exception:
        return pd.DataFrame(columns=['Year', 'TestWeek', 'ProductModel_Suffix', 'RecordCount', 'UniqueProducts'])

def delete_db_data(conn, year, suffix, week):
    """ TEST_HISTORYì™€ PRODUCT í…Œì´ë¸”ì—ì„œ ì¡°ê±´ì— ë§ëŠ” ë°ì´í„°ë¥¼ ì‚­ì œí•©ë‹ˆë‹¤. """
    try:
        cursor = conn.cursor()
        
        find_sn_query = f"""
        SELECT DISTINCT T1.SNumber
        FROM TEST_HISTORY AS T1
        JOIN PRODUCT AS T2 ON T1.SNumber = T2.SNumber
        WHERE T1.TestWeek = '{week}' 
          AND T2.ProductModel_Suffix = '{suffix}' 
          AND strftime('%Y', T1.TestStamp) = '{year}';
        """
        df_sn = pd.read_sql_query(find_sn_query, conn)
        delete_sns = tuple(df_sn['SNumber'].tolist())
        
        if not delete_sns:
            return 0, 0, "ì‚­ì œ ì¡°ê±´ì— ë§ëŠ” SNumberê°€ ì—†ìŠµë‹ˆë‹¤."

        placeholders = ','.join(['?'] * len(delete_sns))

        delete_history_query = f"""
        DELETE FROM TEST_HISTORY
        WHERE TestWeek = '{week}' AND SNumber IN ({placeholders});
        """
        cursor.execute(delete_history_query, delete_sns)
        deleted_history_count = cursor.rowcount
        
        delete_product_query = f"""
        DELETE FROM PRODUCT
        WHERE SNumber IN ({placeholders})
          AND SNumber NOT IN (SELECT SNumber FROM TEST_HISTORY);
        """
        cursor.execute(delete_product_query, delete_sns)
        deleted_product_count = cursor.rowcount
        
        conn.commit()
        return deleted_history_count, deleted_product_count, None

    except Exception as e:
        return 0, 0, str(e)


# ==============================================================================
# 1. Streamlit ì•± ë ˆì´ì•„ì›ƒ
# ==============================================================================

st.set_page_config(layout="wide", page_title="PCB DB ê´€ë¦¬ ì•±")

st.title("PCB ì œì¡° ì´ë ¥ DB ê´€ë¦¬ ë° ë¶„ì„ ğŸ› ï¸")

# --- ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” ---
if 'custom_query_result' not in st.session_state: st.session_state.custom_query_result = None
if 'custom_query_text' not in st.session_state: st.session_state.custom_query_text = """
SELECT * FROM (
    WITH All_Test_Results AS (
        -- TEST_HISTORYì˜ ëª¨ë“  ì¸¡ì •ê°’ì„ TEST_SPECIFICATIONì˜ ëª¨ë“  í•­ëª©ê³¼ ê²°í•©í•©ë‹ˆë‹¤.
        SELECT
            T1.Original_Local_TestID, T1.SNumber, T1.PcbStartTime, T1.PcbStopTime,
            T2.TestItemName, T2.MinLimit, T2.MaxLimit,

            -- ê° TestItemNameì— í•´ë‹¹í•˜ëŠ” ì¸¡ì •ê°’ì„ ì„ íƒí•©ë‹ˆë‹¤.
            CASE
                WHEN T2.TestItemName = 'PcbSleepCurr' THEN T1.PcbSleepCurr_Value
                WHEN T2.TestItemName = 'PcbBatVolt' THEN T1.PcbBatVolt_Value
                WHEN T2.TestItemName = 'PcbIrCurr' THEN T1.PcbIrCurr_Value
                WHEN T2.TestItemName = 'PcbIrPwr' THEN T1.PcbIrPwr_Value
                WHEN T2.TestItemName = 'PcbWirelessVolt' THEN T1.PcbWirelessVolt_Value
                WHEN T2.TestItemName = 'PcbUsbCurr' THEN T1.PcbUsbCurr_Value
                WHEN T2.TestItemName = 'PcbWirelessUsbVolt' THEN T1.PcbWirelessUsbVolt_Value
                WHEN T2.TestItemName = 'PcbLed' THEN T1.PcbLed_Value
                -- ë‹¤ë¥¸ í•­ëª©ì´ ìˆë‹¤ë©´ ì—¬ê¸°ì— ì¶”ê°€í•©ë‹ˆë‹¤.
                ELSE NULL
            END AS Test_Value,

            -- ê° TestItemNameì— ëŒ€í•œ Spec_Result_Detailì„ ê³„ì‚°í•©ë‹ˆë‹¤.
            CASE
                WHEN T2.TestItemName = 'PcbSleepCurr' AND (T1.PcbSleepCurr_Value IS NULL OR T1.PcbSleepCurr_Value = 0.0) THEN 'ì œì™¸'
                WHEN T2.TestItemName = 'PcbBatVolt' AND (T1.PcbBatVolt_Value IS NULL OR T1.PcbBatVolt_Value = 0.0) THEN 'ì œì™¸'
                -- ... ë‹¤ë¥¸ í•­ëª©ì— ëŒ€í•´ì„œë„ 'ì œì™¸' ì¡°ê±´ì„ ì¶”ê°€í•©ë‹ˆë‹¤.
                
                WHEN 
                    CASE
                        WHEN T2.TestItemName = 'PcbSleepCurr' THEN T1.PcbSleepCurr_Value
                        WHEN T2.TestItemName = 'PcbBatVolt' THEN T1.PcbBatVolt_Value
                        WHEN T2.TestItemName = 'PcbIrCurr' THEN T1.PcbIrCurr_Value
                        WHEN T2.TestItemName = 'PcbIrPwr' THEN T1.PcbIrPwr_Value
                        WHEN T2.TestItemName = 'PcbWirelessVolt' THEN T1.PcbWirelessVolt_Value
                        WHEN T2.TestItemName = 'PcbUsbCurr' THEN T1.PcbUsbCurr_Value
                        WHEN T2.TestItemName = 'PcbWirelessUsbVolt' THEN T1.PcbWirelessUsbVolt_Value
                        WHEN T2.TestItemName = 'PcbLed' THEN T1.PcbLed_Value
                        ELSE NULL
                    END > T2.MaxLimit THEN 'ì´ˆê³¼'
                
                WHEN 
                    CASE
                        WHEN T2.TestItemName = 'PcbSleepCurr' THEN T1.PcbSleepCurr_Value
                        WHEN T2.TestItemName = 'PcbBatVolt' THEN T1.PcbBatVolt_Value
                        WHEN T2.TestItemName = 'PcbIrCurr' THEN T1.PcbIrCurr_Value
                        WHEN T2.TestItemName = 'PcbIrPwr' THEN T1.PcbIrPwr_Value
                        WHEN T2.TestItemName = 'PcbWirelessVolt' THEN T1.PcbWirelessVolt_Value
                        WHEN T2.TestItemName = 'PcbUsbCurr' THEN T1.PcbUsbCurr_Value
                        WHEN T2.TestItemName = 'PcbWirelessUsbVolt' THEN T1.PcbWirelessUsbVolt_Value
                        WHEN T2.TestItemName = 'PcbLed' THEN T1.PcbLed_Value
                        ELSE NULL
                    END < T2.MinLimit THEN 'ë¯¸ë‹¬'
                
                WHEN 
                    CASE
                        WHEN T2.TestItemName = 'PcbSleepCurr' THEN T1.PcbSleepCurr_Value
                        WHEN T2.TestItemName = 'PcbBatVolt' THEN T1.PcbBatVolt_Value
                        WHEN T2.TestItemName = 'PcbIrCurr' THEN T1.PcbIrCurr_Value
                        WHEN T2.TestItemName = 'PcbIrPwr' THEN T1.PcbIrPwr_Value
                        WHEN T2.TestItemName = 'PcbWirelessVolt' THEN T1.PcbWirelessVolt_Value
                        WHEN T2.TestItemName = 'PcbUsbCurr' THEN T1.PcbUsbCurr_Value
                        WHEN T2.TestItemName = 'PcbWirelessUsbVolt' THEN T1.PcbWirelessUsbVolt_Value
                        WHEN T2.TestItemName = 'PcbLed' THEN T1.PcbLed_Value
                        ELSE NULL
                    END IS NOT NULL AND 
                    CASE
                        WHEN T2.TestItemName = 'PcbSleepCurr' THEN T1.PcbSleepCurr_Value
                        WHEN T2.TestItemName = 'PcbBatVolt' THEN T1.PcbBatVolt_Value
                        WHEN T2.TestItemName = 'PcbIrCurr' THEN T1.PcbIrCurr_Value
                        WHEN T2.TestItemName = 'PcbIrPwr' THEN T1.PcbIrPwr_Value
                        WHEN T2.TestItemName = 'PcbWirelessVolt' THEN T1.PcbWirelessVolt_Value
                        WHEN T2.TestItemName = 'PcbUsbCurr' THEN T1.PcbUsbCurr_Value
                        WHEN T2.TestItemName = 'PcbWirelessUsbVolt' THEN T1.PcbWirelessUsbVolt_Value
                        WHEN T2.TestItemName = 'PcbLed' THEN T1.PcbLed_Value
                        ELSE NULL
                    END BETWEEN T2.MinLimit AND T2.MaxLimit THEN 'Pass'

                ELSE 'ì œì™¸' -- ì¸¡ì •ê°’ì´ NULLì´ê±°ë‚˜ 0.0ì¸ ê²½ìš°ë¥¼ í¬í•¨
            END AS Spec_Result_Detail

        FROM TEST_HISTORY AS T1
        -- í¬ë¡œìŠ¤ ì¡°ì¸(CROSS JOIN)ì„ ì‚¬ìš©í•˜ì—¬ T1ì˜ ê° í–‰ì´ T2ì˜ ëª¨ë“  TestItemNameê³¼ ì—°ê²°ë˜ë„ë¡ í•©ë‹ˆë‹¤.
        JOIN TEST_SPECIFICATION AS T2 ON 1=1
        
        -- â­â­â­ ë‚ ì§œ í•„í„° ì¶”ê°€ â­â­â­
         WHERE T1.PcbStartTime >= '2025-10-22' AND T1.PcbStartTime < '2025-10-23'
    ),
    
    Product_Status AS (
        -- ì‹œë¦¬ì–¼ ë²ˆí˜¸(SNumber)ë³„ë¡œ í•œ ë²ˆì´ë¼ë„ 'Pass'í•œ ì´ë ¥ì´ ìˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.
        SELECT 
            SNumber, 
            MAX(CASE WHEN Spec_Result_Detail = 'Pass' THEN 1 ELSE 0 END) AS Has_Passed_Flag
        FROM All_Test_Results
        GROUP BY SNumber
    )
    
    SELECT
        ATR.PcbStartTime, ATR.PcbStopTime, ATR.Original_Local_TestID, ATR.SNumber, 
        ATR.TestItemName, ATR.Test_Value, ATR.MinLimit, ATR.MaxLimit,
        ATR.Spec_Result_Detail,
        
        -- ìµœì¢… ë¶ˆëŸ‰ ìœ í˜•ì„ ê²°ì •í•©ë‹ˆë‹¤.
        CASE
            WHEN ATR.Spec_Result_Detail = 'Pass' THEN 'Pass'
            WHEN ATR.Spec_Result_Detail IN ('ë¯¸ë‹¬', 'ì´ˆê³¼', 'ì œì™¸') AND PS.Has_Passed_Flag = 1 THEN 'ê°€ì„±ë¶ˆëŸ‰'
            WHEN ATR.Spec_Result_Detail IN ('ë¯¸ë‹¬', 'ì´ˆê³¼', 'ì œì™¸') AND PS.Has_Passed_Flag = 0 THEN 'ì§„ì„±ë¶ˆëŸ‰'
            ELSE ATR.Spec_Result_Detail
        END AS Final_Failure_Category
        
    FROM All_Test_Results AS ATR
    JOIN Product_Status AS PS ON ATR.SNumber = PS.SNumber
    -- ê²°ê³¼ë¥¼ ì œí•œí•˜ì—¬ ë„ˆë¬´ ë§ì€ í–‰ì´ ë°˜í™˜ë˜ëŠ” ê²ƒì„ ë°©ì§€í•©ë‹ˆë‹¤.
    
)
"""

# "SELECT TestWeek, COUNT(History_PK) FROM TEST_HISTORY GROUP BY TestWeek;"
if 'mode' not in st.session_state: st.session_state.mode = '1. ë°ì´í„° ì €ì¥/ì¶”ê°€ (CSV Insert)'
if 'data_loaded' not in st.session_state: st.session_state.data_loaded = os.path.exists(DB_FILE)
if 'query_limit' not in st.session_state: st.session_state.query_limit = 100
if 'filters' not in st.session_state: st.session_state.filters = []
if 'filtered_df' not in st.session_state: st.session_state.filtered_df = None
if 'uploaded_files_data' not in st.session_state: st.session_state.uploaded_files_data = {}

# # ğŸ’¡ ëˆ„ë½ëœ DB ê²½ë¡œ/íŒŒì¼ëª… ì´ˆê¸°í™” ì¶”ê°€
if 'db_path_input' not in st.session_state: st.session_state.db_path_input = "."
if 'db_name_input' not in st.session_state: st.session_state.db_name_input = DB_FILE
# # ----------------------------------------

# --- ëª¨ë“œ ì„ íƒ ë¼ë””ì˜¤ ë²„íŠ¼ (3ê°€ì§€ ëª¨ë“œ) ---
selected_mode = st.radio( 
    "ì‘ì—… ëª¨ë“œ ì„ íƒ:",
    ['2. DB ì¡°íšŒ ë° ë¶„ì„', '1. ë°ì´í„° ì €ì¥/ì¶”ê°€ (CSV Insert)', '3. ì£¼ì°¨ë³„ DB ë°ì´í„° ì‚­ì œ'],
    # index=['1. ë°ì´í„° ì €ì¥/ì¶”ê°€ (CSV Insert)', '2. DB ì¡°íšŒ ë° ë¶„ì„', '3. ì£¼ì°¨ë³„ DB ë°ì´í„° ì‚­ì œ'].index(st.session_state.mode),
    index=0,
    horizontal=False
)
st.session_state.mode = selected_mode
st.markdown("---")

conn = get_db_connection(DB_FILE)

# ==============================================================================
# MODE 1: ë°ì´í„° ì €ì¥/ì¶”ê°€ ë¡œì§
# ==============================================================================
if st.session_state.mode == '1. ë°ì´í„° ì €ì¥/ì¶”ê°€ (CSV Insert)':
    st.header("1. CSV íŒŒì¼ ì—…ë¡œë“œ ë° DB ëˆ„ì  ì €ì¥")

    # 1. DB í˜„í™©íŒ í‘œì‹œ
    df_status = get_db_status(conn)
    st.subheader("í˜„ì¬ DBì— ì €ì¥ëœ ì£¼ì°¨ë³„ ìƒì„¸ ë°ì´í„° í˜„í™©")
    if not df_status.empty:
        st.dataframe(df_status, use_container_width=True)
    else:
        st.info("DBì— ì €ì¥ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. CSV íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì—¬ DBë¥¼ ìƒì„±í•˜ì„¸ìš”.")

    st.markdown("---")
    st.subheader("ìƒˆ CSV ë°ì´í„° ì²˜ë¦¬")

    # 2. ì—…ë¡œë“œí•  ì£¼ì°¨/ëª¨ë¸ ì„ íƒ UI
    col_week, col_suffix = st.columns(2)
    with col_week:
        selected_week = st.selectbox("1. ì—…ë¡œë“œí•  ë°ì´í„° ì£¼ì°¨ ì„ íƒ (WXX)", options=['W38', 'W39', 'W40', 'W41', 'W42', 'W43', 'UNKNOWN'], key='input_week_select')
    with col_suffix:
        selected_suffix = st.text_input("2. ProductModel_Suffix ì…ë ¥ (ì˜ˆ: PCB)", value="PCB", key='input_suffix_text')

    uploaded_files = st.file_uploader(
        "3. CSV íŒŒì¼ ì—…ë¡œë“œ (ë³µìˆ˜ íŒŒì¼ ê°€ëŠ¥)",
        type=['csv'],
        accept_multiple_files=True,
        key='insert_uploader',
        on_change=lambda: st.session_state.uploaded_files_data.clear() # ìƒˆ íŒŒì¼ ì—…ë¡œë“œ ì‹œ ì´ì „ ë°ì´í„° ì´ˆê¸°í™”
    )
    
    # 3. íŒŒì¼ ì—…ë¡œë“œ ì‹œ ì¦‰ì‹œ ë°ì´í„° ì²˜ë¦¬ ë° ë¯¸ë¦¬ë³´ê¸°
    if uploaded_files:
        st.markdown("---")
        st.subheader("4. ì—…ë¡œë“œ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° ë° ì €ì¥ í•„ë“œ ì„ íƒ")
        
        files_data_to_process = {} # ì„ì‹œ ì €ì¥ì†Œ
        
        for file in uploaded_files:
            file_key = file.name
            
            # íŒŒì¼ì´ ì„¸ì…˜ ìƒíƒœì— ì—†ìœ¼ë©´ ì²˜ë¦¬ ì‹œì‘
            if file_key not in st.session_state.uploaded_files_data:
                
                # ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ (ìºì‹œ í•¨ìˆ˜ í˜¸ì¶œ)
                df_prod, df_spec, df_hist = load_data_with_dynamic_header(file, selected_week)
                
                if df_hist is not None:
                    initial_cols = df_hist.columns.tolist()
                    st.session_state.uploaded_files_data[file_key] = {
                        'df_prod': df_prod,
                        'df_spec': df_spec,
                        'df_history_original': df_hist,
                        'selected_cols': initial_cols, # ì´ˆê¸°ì—ëŠ” ëª¨ë“  ì»¬ëŸ¼ ì„ íƒ
                        'test_week': selected_week
                    }
        
        # 4. ë¯¸ë¦¬ë³´ê¸° UI ë° í•„ë“œ ì„ íƒ
        
        total_rows_to_save = 0
        
        for file_key, data in st.session_state.uploaded_files_data.items():
            total_rows_to_save += len(data['df_history_original'])
            
            # ğŸ’¡ íŒŒì¼ë³„ Expanderì™€ í•„ë“œ ì„ íƒ UI
            with st.expander(f"ğŸ“ íŒŒì¼: {file_key} (ì£¼ì°¨: {data['test_week']}, ì´ {len(data['df_history_original'])}í–‰)", expanded=True):
                
                st.markdown("##### ì €ì¥í•  í•„ë“œ ì„ íƒ/ì œê±°")
                all_cols = data['df_history_original'].columns.tolist()
                
                # Multiselect ìœ„ì ¯ì„ ì‚¬ìš©í•˜ì—¬ í•„ë“œ ì„ íƒ
                selected_cols = st.multiselect(
                    "í•„ë“œëª… ì¶”ê°€ ë˜ëŠ” ì œê±°",
                    options=all_cols,
                    default=data['selected_cols'], # ì´ì „ ì„ íƒê°’ ìœ ì§€
                    key=f'multiselect_insert_{file_key}' # ê³ ìœ  í‚¤ ì‚¬ìš©
                )
                
                # ì„ íƒëœ ì»¬ëŸ¼ì„ ì„¸ì…˜ ìƒíƒœì— ì €ì¥ (ë‹¤ìŒ ì €ì¥ ë²„íŠ¼ í´ë¦­ ì‹œ ì‚¬ìš©)
                st.session_state.uploaded_files_data[file_key]['selected_cols'] = selected_cols
                
                # ë¯¸ë¦¬ë³´ê¸° í…Œì´ë¸” ì¶œë ¥ (ì„ íƒëœ ì»¬ëŸ¼ë§Œ)
                if selected_cols:
                    df_preview = data['df_history_original'][selected_cols].head(5)
                    st.markdown("##### ğŸ“„ ë¯¸ë¦¬ë³´ê¸° (ì„ íƒ í•„ë“œ)")
                    st.dataframe(df_preview, use_container_width=True)
        
        st.markdown("---")
        st.markdown(f"#### ğŸ’¾ ìµœì¢… ì €ì¥ ì˜ˆì • í–‰ ìˆ˜: {total_rows_to_save} í–‰")
        
        # 5. ìµœì¢… ì €ì¥ ë²„íŠ¼
        if st.button("DBì— ë°ì´í„° ì €ì¥/ì¶”ê°€ ì‹¤í–‰", key='final_save_btn'):
            
            total_rows_added = 0
            
            for file_key, data in st.session_state.uploaded_files_data.items():
                
                df_hist_filtered = data['df_history_original'][data['selected_cols']].copy()
                data['df_prod']['ProductModel_Suffix'] = selected_suffix
                
                success, added_rows = save_dataframes_to_db(
                    conn, 
                    data['df_prod'], 
                    data['df_spec'], 
                    df_hist_filtered # í•„í„°ë§ëœ DF ì „ë‹¬
                )
                if success:
                    st.success(f"âœ”ï¸ {file_key} ({data['test_week']}) íŒŒì¼ ë°ì´í„° {added_rows}í–‰ DBì— ì„±ê³µì ìœ¼ë¡œ ì¶”ê°€.")
                    total_rows_added += added_rows

            if total_rows_added > 0:
                st.toast(f"ì´ {total_rows_added}í–‰ì˜ ë°ì´í„°ê°€ DBì— ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.", icon='ğŸ‰')
                st.session_state.data_loaded = True
                st.session_state.uploaded_files_data = {} # ì €ì¥ ì™„ë£Œ í›„ ì´ˆê¸°í™”
                st.rerun() # UI ê°±ì‹ 
            else:
                st.warning("DBì— ì €ì¥ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ì €ì¥ëœ íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
                
    elif not os.path.exists(DB_FILE):
         st.info("DB íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. CSV íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì—¬ DBë¥¼ ìƒì„±í•˜ì„¸ìš”.")


# ==============================================================================
# MODE 2: DB ì¡°íšŒ ë° ë¶„ì„ ë¡œì§
# ==============================================================================
elif st.session_state.mode == '2. DB ì¡°íšŒ ë° ë¶„ì„':
    st.header("2. DB í…Œì´ë¸” ì¡°íšŒ ë° ê´€ë¦¬")
#  ########   
    # # ğŸ’¡ DB íŒŒì¼ ê²½ë¡œ ì…ë ¥ UI
    # st.subheader("DB ì—°ê²° ì„¤ì •")
    # # col_db_path, col_db_name = st.columns([2, 1])
    # col_db_path, col_db_name, col_db_download = st.columns([2, 1, 1])
    
    # with col_db_path:
    #     # ê²½ë¡œ ì…ë ¥ í•„ë“œ
    #     db_path = st.text_input("DB íŒŒì¼ ê²½ë¡œ (ì˜ˆ: C:/data ë˜ëŠ” .)", value=st.session_state.db_path_input, key='db_path_mode2')
    #     st.session_state.db_path_input = db_path
    
    # with col_db_name:
    #     # íŒŒì¼ëª… ì…ë ¥ í•„ë“œ
    #     db_name = st.text_input("DB íŒŒì¼ëª… (ì˜ˆ: analysis.db)", value=st.session_state.db_name_input, key='db_name_mode2')
    #     st.session_state.db_name_input = db_name
# ############
    # 1. DB í˜„í™©íŒ ì—…ë°ì´íŠ¸ ë° ì´ˆê¸° ì¿¼ë¦¬ ì‹¤í–‰
    df_status = get_db_status(conn)
    st.subheader("DBì— ì €ì¥ëœ ì£¼ì°¨ë³„ ìƒì„¸ ë°ì´í„° í˜„í™© (í˜„ì¬ ì—°ê²° íŒŒì¼: {DB_FILE_DEFAULT})")
    if not df_status.empty:
        st.dataframe(df_status, use_container_width=True)
        # ğŸ’¡ ëª¨ë“œ ì „í™˜ ì‹œ ì´ˆê¸° ì¿¼ë¦¬ ì‹¤í–‰
        if st.session_state.custom_query_result is None:
            try:
                df_initial = pd.read_sql_query(st.session_state.custom_query_text, conn)
                st.session_state.custom_query_result = df_initial
                st.session_state.filters = []
                st.session_state.filtered_df = df_initial.copy()
            except Exception:
                pass 
    else:
        st.info("DB íŒŒì¼ì´ ì´ˆê¸°í™”ë˜ì—ˆê±°ë‚˜ TEST_HISTORY í…Œì´ë¸”ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

#      ########   
#     # ğŸ’¡ DB íŒŒì¼ ê²½ë¡œ ì…ë ¥ UI
#     st.subheader("DB ì—°ê²° ì„¤ì •")
#     col_db_path, col_db_name = st.columns([2, 1])

#     with col_db_path:
#         # ê²½ë¡œ ì…ë ¥ í•„ë“œ
#         db_path = st.text_input("DB íŒŒì¼ ê²½ë¡œ (ì˜ˆ: C:/data ë˜ëŠ” .)", value=st.session_state.db_path_input, key='db_path_mode2')
#         st.session_state.db_path_input = db_path
    
#     with col_db_name:
#         # íŒŒì¼ëª… ì…ë ¥ í•„ë“œ
#         db_name = st.text_input("DB íŒŒì¼ëª… (ì˜ˆ: analysis.db)", value=st.session_state.db_name_input, key='db_name_mode2')
#         st.session_state.db_name_input = db_name
# ############
##################
    # ğŸ’¡ ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ ë¡œì§
    
    # full_db_path_download = os.path.join(db_path, db_name)
    
    # with col_db_download:
    #     st.markdown("<br>", unsafe_allow_html=True) # UI ì •ë ¬ìš©
        
    #     # íŒŒì¼ì´ ì‹¤ì œë¡œ ì¡´ì¬í•˜ê³  ì—°ê²°ì´ ì„±ê³µí–ˆì„ ë•Œë§Œ ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ í‘œì‹œ
    #     if os.path.exists(full_db_path_download):
    #         with open(full_db_path_download, "rb") as file:
    #             st.download_button(
    #                 label="DB íŒŒì¼ ë‹¤ìš´ë¡œë“œ (.db)",
    #                 data=file,
    #                 file_name=db_name, # ì…ë ¥ëœ DB íŒŒì¼ëª… ì‚¬ìš©
    #                 mime="application/octet-stream"
    #             )
    #     else:
    #         st.info("DB íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•Šê±°ë‚˜ ê²½ë¡œê°€ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤.")
            
################
#############
    # ğŸ’¡ DB ë‹¤ìš´ë¡œë“œ ê¸°ëŠ¥ (í˜„í™©íŒ ë°‘ì— ìƒì„±)
    st.markdown("---")
    st.subheader("DB íŒŒì¼ ë‹¤ë¥¸ ì´ë¦„ìœ¼ë¡œ ì €ì¥ (ë‹¤ìš´ë¡œë“œ)")
    
    col_name, col_download_btn = st.columns([3, 1])

    with col_name:
        db_name = st.text_input("ë‹¤ìš´ë¡œë“œ ì‹œ ì €ì¥í•  íŒŒì¼ëª… ì…ë ¥ (.db í¬í•¨)", value=st.session_state.db_name_input, key='db_name_download')
        st.session_state.db_name_input = db_name

    with col_download_btn:
        st.markdown("<br>", unsafe_allow_html=True)
        
        if os.path.exists(DB_FILE):
            try:
                with open(DB_FILE, "rb") as file:
                    st.download_button(
                        label="DB íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì‹¤í–‰",
                        data=file,
                        file_name=db_name,
                        mime="application/octet-stream",
                        key='db_download_final_btn'
                    )
            except Exception as e:
                st.error(f"DB íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")
        else:
            st.warning(f"í˜„ì¬ ì—°ê²°ëœ DB íŒŒì¼({DB_FILE})ì´ ë””ìŠ¤í¬ì— ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

    st.markdown("---")
        
    ####################333    
    # 2. ë©”ì¸ ì¡°íšŒ ë° í•„í„°ë§ ë¡œì§
    if not get_table_names(conn):
        st.warning(f"DB íŒŒì¼ì— í…Œì´ë¸”ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ëª¨ë“œ 1ì—ì„œ ë¨¼ì € ë°ì´í„°ë¥¼ ì €ì¥í•´ì£¼ì„¸ìš”.")
    else:
################
        # # ğŸ’¡ ê¸°ê°„ ì…ë ¥ ìœ„ì ¯
        # st.markdown("##### ğŸ“… ì¿¼ë¦¬ ê¸°ê°„ ì„¤ì • (PcbStartTime ê¸°ì¤€)")
        # # today = datetime.now().date()
        # # default_start = today - timedelta(days=30)
        # today_date, default_start_date = get_default_dates() # ğŸ’¡ í•¨ìˆ˜ í˜¸ì¶œë¡œ ë³€ìˆ˜ ìƒì„±

        # col_date_from, col_date_to = st.columns(2)
        # with col_date_from:
        #     date_from = st.date_input("FROM Date", value=default_start_date, key='date_from_input')
        # with col_date_to:
        #     date_to = st.date_input("TO Date", value=today_date, key='date_to_input')
 ######################       
        # --- 2-1. í…Œì´ë¸” ëª©ë¡ ì„ íƒ ë° í•„ë“œ í¸ì§‘ ---
        # (ì´ì „ ë‹µë³€ì˜ 2-1 ë¡œì§ ì¬ë°°ì¹˜)
        st.markdown("---")
        st.subheader("2-1. í…Œì´ë¸” í•„ë“œ ì„ íƒ ì¡°íšŒ (Raw Data)")
        table_names = get_table_names(conn)
        col_select, col_display = st.columns([1, 2])
        
        with col_select:
            selected_table = st.selectbox("ì¡°íšŒí•  í…Œì´ë¸” ì„ íƒ", table_names, key='table_select_2_1')
        
        try:
            df_full = pd.read_sql_query(f"SELECT * FROM {selected_table} LIMIT 100", conn)
            
            with col_select:
                all_columns = df_full.columns.tolist()
                selected_columns = st.multiselect(
                    "í•„ë“œëª… ì¶”ê°€ ë˜ëŠ” ì œê±°", 
                    all_columns, 
                    default=all_columns,
                    key=f'multiselect_{selected_table}'
                )
            
            if selected_columns:
                columns_str = ", ".join([f'"{c}"' for c in selected_columns])
                query_filtered = f"SELECT {columns_str} FROM {selected_table}"
                df_filtered = pd.read_sql_query(query_filtered, conn)
                
                with col_display:
                    st.markdown(f"**í…Œì´ë¸” `{selected_table}` ì¡°íšŒ ê²°ê³¼ (ì„ íƒ í•„ë“œ)**")
                    st.dataframe(df_filtered.head(100), use_container_width=True)
            else:
                with col_display:
                    st.info("ì¡°íšŒí•  í•„ë“œë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")
                    
        except Exception as e:
            st.error(f"í…Œì´ë¸” ì¡°íšŒ ì˜¤ë¥˜: {e}")
  ###################      
        # # ğŸ’¡ ê¸°ê°„ ì…ë ¥ ìœ„ì ¯
        # st.markdown("##### ğŸ“… ì¿¼ë¦¬ ê¸°ê°„ ì„¤ì • (PcbStartTime ê¸°ì¤€)")
        # # today = datetime.now().date()
        # # default_start = today - timedelta(days=30)
        # today_date, default_start_date = get_default_dates() # ğŸ’¡ í•¨ìˆ˜ í˜¸ì¶œë¡œ ë³€ìˆ˜ ìƒì„±

        # col_date_from, col_date_to = st.columns(2)
        # with col_date_from:
        #     date_from = st.date_input("FROM Date", value=default_start_date, key='date_from_input')
        # with col_date_to:
        #     date_to = st.date_input("TO Date", value=today_date, key='date_to_input')
 ####################           
        # --- 2-2. ì‚¬ìš©ì ì§ì ‘ SQL ì¿¼ë¦¬ ì‹¤í–‰ ë° í•„ë“œ í¸ì§‘ ---
        st.markdown("---")
        st.subheader("2-2. ì‚¬ìš©ì ì§ì ‘ SQL ì¿¼ë¦¬ ì‹¤í–‰ ë° ë©€í‹° í•„í„°ë§")
        # ##########
        # # ğŸ’¡ ê¸°ê°„ ì…ë ¥ ìœ„ì ¯
        # st.markdown("##### ğŸ“… ì¿¼ë¦¬ ê¸°ê°„ ì„¤ì • (PcbStartTime ê¸°ì¤€)")
        # today = datetime.now().date()
        # default_start = today - timedelta(days=30)
        
        # col_date_from, col_date_to = st.columns(2)
        # with col_date_from:
        #     date_from = st.date_input("FROM Date", value=default_start, key='date_from_input')
        # with col_date_to:
        #     date_to = st.date_input("TO Date", value=today, key='date_to_input')
        
        # ########
        col_sql, col_limit = st.columns([2, 1])

        with col_sql:
            sql_query = st.text_area("ì‹¤í–‰í•  SQL ì¿¼ë¦¬ ì…ë ¥ (SELECT ë˜ëŠ” WITHë¡œ ì‹œì‘)", value=st.session_state.custom_query_text, height=150, key='sql_input')
            
        with col_limit:
            st.markdown("##### ğŸ“Œ ì¿¼ë¦¬ ê²°ê³¼ LIMIT ì„¤ì •")
            # (Total Count ë° LIMIT ì…ë ¥ ë¡œì§)
            total_rows, error_msg = get_total_count_for_query(conn, sql_query)
            if total_rows is not None: st.markdown(f"**ì´ ì˜ˆìƒ í–‰ ê°œìˆ˜:** (`{total_rows}í–‰`)")
            else: st.info(f"ì´ í–‰ ê°œìˆ˜ í™•ì¸ ë¶ˆê°€ ({error_msg})")
            
            new_limit_str = st.text_input("LIMIT ê°’ ì…ë ¥ (ê¸°ë³¸: 100)", value=str(st.session_state.query_limit), key='custom_limit_input')
            
            if st.button("SQL ì¿¼ë¦¬ ì‹¤í–‰", key='run_sql_button'):
                try:
                    final_limit = int(new_limit_str) if new_limit_str.strip().isdigit() and int(new_limit_str) > 0 else st.session_state.query_limit
                    cleaned_query = re.sub(r'LIMIT\s+\d+\s*;?\s*$', '', sql_query.strip(), flags=re.IGNORECASE).rstrip('; ')
                    final_query = f"{cleaned_query} LIMIT {final_limit}"
                    
                    df_custom = pd.read_sql_query(final_query, conn)
                    st.session_state.custom_query_result = df_custom.copy()
                    st.session_state.filters = []
                    st.session_state.filtered_df = df_custom.copy()
                    st.success(f"ì¿¼ë¦¬ ì‹¤í–‰ ì„±ê³µ! (LIMIT: {final_limit})")

                except Exception as e:
                    st.error(f"âŒ SQL ì‹¤í–‰ ì˜¤ë¥˜: {e}")
                    st.session_state.custom_query_result = None 
                    
        # ##########
        # # ğŸ’¡ ê¸°ê°„ ì…ë ¥ ìœ„ì ¯
        # st.markdown("##### ğŸ“… ì¿¼ë¦¬ ê¸°ê°„ ì„¤ì • (PcbStartTime ê¸°ì¤€)")
        # # today = datetime.now().date()
        # # default_start = today - timedelta(days=30)
        # today_date, default_start_date = get_default_dates() # ğŸ’¡ í•¨ìˆ˜ í˜¸ì¶œë¡œ ë³€ìˆ˜ ìƒì„±

        # col_date_from, col_date_to = st.columns(2)
        # with col_date_from:
        #     date_from = st.date_input("FROM Date", value=default_start_date, key='date_from_input')
        # with col_date_to:
        #     date_to = st.date_input("TO Date", value=today_date, key='date_to_input')

        # col_date_from, col_date_to = st.columns(2)
        # with col_date_from:
        #     date_from = st.date_input("FROM Date", value=default_start, key='date_from_input')
        # with col_date_to:
        #     date_to = st.date_input("TO Date", value=today, key='date_to_input')
        
        # ########

        # ğŸ’¡ ê²°ê³¼ ì¶œë ¥ ë° í•„ë“œ í¸ì§‘/ê²€ìƒ‰ ë¡œì§
        if st.session_state.custom_query_result is not None:
            
            df_full_result = st.session_state.custom_query_result.copy()
            all_result_columns = df_full_result.columns.tolist()
            
            # --- 3. ìµœì¢… ê²°ê³¼ í…Œì´ë¸” ì¶œë ¥ (ìƒë‹¨) ---
            st.markdown("---")
            st.markdown("##### ğŸ“Œ SQL ì¿¼ë¦¬ ì‹¤í–‰ ê²°ê³¼")
            
            df_to_display = st.session_state.filtered_df if st.session_state.filtered_df is not None else df_full_result
            
            selected_final_columns = st.multiselect("3. ìµœì¢… ì¶œë ¥ í•„ë“œ ì„ íƒ", all_result_columns, default=all_result_columns, key='final_output_selector_vertical')
            
            if selected_final_columns:
                df_edited = df_to_display[selected_final_columns]
                st.markdown(f"**SQL ì¿¼ë¦¬ ê²°ê³¼ (ì´ {len(df_to_display)}ê±´)**")
                st.dataframe(df_edited, use_container_width=True) 

            st.markdown("---") 
            st.markdown("##### âœ¨ 1. ê²€ìƒ‰ ì¡°ê±´ ì¶”ê°€/ê´€ë¦¬")

            # --- í•„í„° ì¡°ê±´ ì¶”ê°€ UI ---
            col_add_field, col_add_op, col_add_value, col_add_btn = st.columns([1, 0.7, 1.3, 0.5])
            with col_add_field: filter_col_add = st.selectbox("í•„ë“œ", options=all_result_columns, key='filter_col_add_key')
            with col_add_op: filter_op_add = st.selectbox("ì¡°ê±´", options=['í¬í•¨', 'ì¼ì¹˜', 'ì‹œì‘', 'ì¢…ë£Œ'], key='filter_op_add_key')
            with col_add_value: filter_value_add = st.text_input("ê²€ìƒ‰ ê°’", value="", key='filter_value_add_key')
            with col_add_btn:
                st.markdown("<br>", unsafe_allow_html=True)
                if st.button("í•„í„° ì¶”ê°€", key='add_filter_btn'):
                    if filter_value_add:
                        st.session_state.filters.append({'col': filter_col_add, 'op': filter_op_add, 'val': filter_value_add})
                        st.success(f"í•„í„° ì¶”ê°€ë¨: {filter_col_add} {filter_op_add} '{filter_value_add}'")
                    else:
                        st.warning("ê²€ìƒ‰ ê°’ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")

            st.markdown("---")
            st.markdown("##### 2. í˜„ì¬ ì ìš©ëœ í•„í„° ëª©ë¡")

            # --- í˜„ì¬ í•„í„° ëª©ë¡ ë° ì œê±° UI ---
            if st.session_state.filters:
                for i, f in enumerate(st.session_state.filters):
                    col_view, col_remove = st.columns([3, 0.5])
                    with col_view: st.write(f"**{i+1}.** `{f['col']}` {f['op']} **'{f['val']}'**")
                    with col_remove:
                        if st.button("ì œê±°", key=f'remove_filter_{i}'):
                            st.session_state.filters.pop(i)
                            st.rerun() 

            else:
                st.info("ì¶”ê°€ëœ ê²€ìƒ‰ ì¡°ê±´ì´ ì—†ìŠµë‹ˆë‹¤.")

            st.markdown("---")
            
            # --- ê²€ìƒ‰ ì‹œì‘ ë²„íŠ¼ ë° í•„í„°ë§ ë¡œì§ ---
            if st.button("ê²€ìƒ‰ ì‹œì‘", key='apply_search_btn'):
                df_filtered = df_full_result.copy()
                
                for f in st.session_state.filters:
                    col, op, val = f['col'], f['op'], f['val']
                    if col in df_filtered.columns:
                        series = df_filtered[col].astype(str).str.lower()
                        val_lower = str(val).lower()
                        
                        if op == 'í¬í•¨': df_filtered = df_filtered[series.str.contains(val_lower, na=False)]
                        elif op == 'ì¼ì¹˜': df_filtered = df_filtered[series == val_lower]
                        elif op == 'ì‹œì‘': df_filtered = df_filtered[series.str.startswith(val_lower, na=False)]
                        elif op == 'ì¢…ë£Œ': df_filtered = df_filtered[series.str.endswith(val_lower, na=False)]
                
                st.session_state.filtered_df = df_filtered.copy()
                st.success(f"ê²€ìƒ‰ ê²°ê³¼ ì ìš© ì™„ë£Œ! ì´ {len(df_filtered)}ê±´ ì¡°íšŒë˜ì—ˆìŠµë‹ˆë‹¤.")


# ==============================================================================
# MODE 3: ì£¼ì°¨ë³„ DB ë°ì´í„° ì‚­ì œ ë¡œì§
# ==============================================================================
elif st.session_state.mode == '3. ì£¼ì°¨ë³„ DB ë°ì´í„° ì‚­ì œ':
    st.header("3. ì£¼ì°¨ë³„ ë°ì´í„° ì‚­ì œ")
    st.warning("âš ï¸ ê²½ê³ : ë°ì´í„° ì‚­ì œëŠ” ë˜ëŒë¦´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì¡°ê±´ì„ ì •í™•íˆ í™•ì¸í•˜ì„¸ìš”.")

    df_status = get_db_status(conn)
    
    if df_status.empty:
        st.error("ì‚­ì œí•  ë°ì´í„°ê°€ DBì— ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. '2. DB ì¡°íšŒ ë° ë¶„ì„' ëª¨ë“œì—ì„œ í™•ì¸í•˜ì„¸ìš”.")
    else:
        st.markdown("##### í˜„ì¬ DB í˜„í™© (ì‚­ì œ ê¸°ì¤€)")
        st.dataframe(df_status, use_container_width=True)

        # 2. ì¡°ê±´ ì„ íƒ UI
        st.markdown("---")
        st.subheader("ì‚­ì œí•  ì£¼ì°¨/ëª¨ë¸ ì„ íƒ")

        col_year, col_suffix, col_week = st.columns(3)
        
        unique_years = df_status['Year'].unique().tolist()
        unique_suffixes = df_status['ProductModel_Suffix'].unique().tolist()

        with col_year:
            year_to_delete = st.selectbox("1. ì‚­ì œí•  ì—°ë„ ì„ íƒ", unique_years)
        with col_suffix:
            suffix_to_delete = st.selectbox("2. ì‚­ì œí•  ProductModel_Suffix ì„ íƒ", unique_suffixes)
        
        filtered_weeks = df_status[
            (df_status['Year'] == year_to_delete) & 
            (df_status['ProductModel_Suffix'] == suffix_to_delete)
        ]['TestWeek'].unique().tolist()

        with col_week:
            week_to_delete = st.selectbox("3. ì‚­ì œí•  ì£¼ì°¨(TestWeek) ì„ íƒ", filtered_weeks)

        # 3. ì‚­ì œ í™•ì¸ ë²„íŠ¼
        st.markdown("---")
        if st.button(f"ìœ„ ì¡°ê±´ìœ¼ë¡œ ë°ì´í„° ì‚­ì œ ì‹¤í–‰", type="primary"):
            
            hist_count, prod_count, error = delete_db_data(
                conn, year_to_delete, suffix_to_delete, week_to_delete
            )
            
            if error is None:
                st.success(f"âœ… ë°ì´í„° ì‚­ì œ ì„±ê³µ!")
                st.markdown(f"- **TEST_HISTORY** í…Œì´ë¸”ì—ì„œ **{hist_count}í–‰** ì‚­ì œë¨.")
                st.markdown(f"- **PRODUCT** í…Œì´ë¸”ì—ì„œ **{prod_count}í–‰** ì‚­ì œë¨ (ë‹¤ë¥¸ ê¸°ë¡ì´ ì—†ëŠ” ì œí’ˆ).")
                st.info("í˜„í™©ì„ ê°±ì‹ í•©ë‹ˆë‹¤. '2. DB ì¡°íšŒ ë° ë¶„ì„' ëª¨ë“œë¥¼ ë‹¤ì‹œ ì„ íƒí•˜ì„¸ìš”.")
                st.rerun() 

            else:
                st.error(f"âŒ ë°ì´í„° ì‚­ì œ ì˜¤ë¥˜ ë°œìƒ: {error}")
