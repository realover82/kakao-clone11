import streamlit as st
import pandas as pd
import sqlite3
import os
from datetime import datetime, timedelta
import matplotlib.pyplot as plt
import seaborn as sns 
import matplotlib as mpl
import numpy as np

# ----------------- âš ï¸ í°íŠ¸ ë° ìŠ¤íƒ€ì¼ ì„¤ì • âš ï¸ -----------------
# ì± íŠ¸ í•œê¸€ ê¹¨ì§ ë°©ì§€ ì„¤ì • ë° ìŠ¤íƒ€ì¼
plt.rcParams['font.family'] = 'Malgun Gothic'
mpl.rcParams['axes.unicode_minus'] = False 

# ----------------- âš ï¸ ìƒìˆ˜ ì •ì˜ âš ï¸ -----------------
DB_FILE_NAME = r'./product_quality_db_final_stable-74.db' 
DATE_COLUMN_MAP = {'fw': 'FwStamp', 'rftx': 'RfTxStamp', 'batadc': 'BatadcStamp', 'semi': 'SemiAssyStartTime', 'pcb': 'PcbStartTime'}
ITEM_OPTIONS = ('pcb', 'semi', 'fw', 'rftx', 'batadc')
DB_TABLES = ['T_MASTER_DATA', 'T_ITEM_PCB', 'T_ITEM_SEMI', 'T_ITEM_FW', 'T_ITEM_RFTX', 'T_ITEM_BATADC', 'T_PC_INFO', 'T_SPEC_PCB', 'T_SPEC_SEMI']

# PC ì»¬ëŸ¼ëª… (ìŠ¤í‚¤ë§ˆ í™•ì¸ ê²°ê³¼)
PC_COLUMN_NAME = 'PC_ID'

# ==========================================================
# DB ì €ì¥ ê´€ë ¨ í—¬í¼ í•¨ìˆ˜ë“¤
# ==========================================================

def calculate_week_number(date_str):
    """'YYYY-MM-DD HH:MM:SS' í˜•ì‹ì—ì„œ ISO ì£¼ì°¨(YYYY-W##)ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤."""
    try:
        dt = datetime.strptime(date_str, '%Y-%m-%d %H:%M:%S')
        return f"{dt.year}-W{dt.isocalendar()[1]:02d}"
    except:
        return None

def transform_datetime_columns(df_source, columns_to_transform):
    """Epoch ë˜ëŠ” YYYYMMDDhhmmss.f í˜•íƒœì˜ ìˆ«ì ì»¬ëŸ¼ì„ ë¬¸ìì—´ ë‚ ì§œë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    for col in columns_to_transform:
        if col in df_source.columns:
            
            # âœ… FutureWarning í•´ê²°: ëª…ì‹œì ìœ¼ë¡œ ì»¬ëŸ¼ì„ object íƒ€ì…ìœ¼ë¡œ ë³€í™˜ í›„ ë¬¸ìì—´ í• ë‹¹
            if df_source[col].dtype in ['float64', 'int64']:
                df_source[col] = df_source[col].astype('object')
                mask = df_source[col].notna()
                df_source.loc[mask, col] = df_source.loc[mask, col].astype(str)

            dt_str_series = df_source[col].astype(str).str.split(r'\.', expand=True)[0]
            is_potential_datetime = (dt_str_series.str.len() >= 14) & (dt_str_series.str.startswith('20'))
            
            try:
                dt_series_format = pd.to_datetime(dt_str_series.where(is_potential_datetime), format='%Y%m%d%H%M%S', errors='coerce')
                mask_success = dt_series_format.notna()
                if mask_success.any():
                    formatted_dates = dt_series_format[mask_success].dt.strftime('%Y-%m-%d %H:%M:%S')
                    df_source.loc[mask_success, col] = formatted_dates.values
            except ValueError: pass
            
            if df_source[col].dtype != 'object':
                df_source[col] = df_source[col].astype(str)
            
            is_numeric_epoch = df_source[col].str.contains(r'^\d+\.\d+$', na=False).fillna(False)
            
            try:
                if is_numeric_epoch.any():
                    dt_series_epoch = pd.to_datetime(df_source.loc[is_numeric_epoch, col].astype(float), unit='ms', origin='unix', errors='coerce', utc=True).dt.tz_convert('Asia/Seoul')
                    str_series_epoch = dt_series_epoch.dt.strftime('%Y-%m-%d %H:%M:%S')
                    mask_success_epoch = str_series_epoch.notna()
                    if mask_success_epoch.any():
                        df_source.loc[is_numeric_epoch, col] = str_series_epoch.values
            except: pass
            
            df_source[col] = df_source[col].astype(str).replace('nan', None, regex=True)
            df_source.loc[df_source[col] == '<NA>', col] = None
                
    return df_source

def create_initial_db_schema(cursor, conn):
    """DB ì´ˆê¸° ìŠ¤í‚¤ë§ˆë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    cursor.execute("PRAGMA foreign_keys = ON;")
    
    # 1. T_MASTER_DATA
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS T_MASTER_DATA (
            SNumber TEXT PRIMARY KEY,
            ICount INTEGER,
            Stamp TEXT,
            FwPass TEXT,          
            BatPass TEXT,         
            RfTxPass TEXT,        
            PcbPass TEXT,         
            SemiAssyPass TEXT,    
            BatadcPass TEXT,      
            WEEK_NO TEXT 
        );
    """)
    
    # âœ… ê¸°ì¡´ í…Œì´ë¸”ì— WEEK_NO ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ì¶”ê°€
    try:
        cursor.execute("SELECT WEEK_NO FROM T_MASTER_DATA LIMIT 1")
    except:
        try:
            cursor.execute("ALTER TABLE T_MASTER_DATA ADD COLUMN WEEK_NO TEXT")
            conn.commit()
            print("âœ… T_MASTER_DATAì— WEEK_NO ì»¬ëŸ¼ì„ ì¶”ê°€í–ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            print(f"âš ï¸ WEEK_NO ì»¬ëŸ¼ ì¶”ê°€ ì‹¤íŒ¨ (ì´ë¯¸ ì¡´ì¬í•  ìˆ˜ ìˆìŒ): {e}")

    # 2. T_PC_INFO
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS T_PC_INFO (
            PC_ID TEXT PRIMARY KEY,
            PC_Type TEXT
        );
    """)
    
    # 3. T_SPEC_PCB
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS T_SPEC_PCB (
            Spec_ID INTEGER PRIMARY KEY,
            Measure_Item TEXT,
            Min_Value REAL,
            Max_Value REAL,
            Start_Date TEXT,
            Spec_Key TEXT UNIQUE
        );
    """)
    
    # 4. T_SPEC_SEMI
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS T_SPEC_SEMI (
            Spec_ID INTEGER PRIMARY KEY,
            Measure_Item TEXT,
            Min_Value REAL,
            Max_Value REAL,
            Start_Date TEXT,
            Spec_Key TEXT UNIQUE
        );
    """)
    
    # 5. T_ITEM_PCB
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS T_ITEM_PCB (
            SNumber TEXT,
            PcbStartTime TEXT,
            PcbStopTime TEXT,
            PcbPass TEXT,
            PcbSleepCurr REAL,
            PcbBatVolt REAL,
            PcbIrCurr REAL,
            PcbIrPwr REAL,
            PcbWirelessVolt REAL,
            PcbUsbCurr REAL,
            PcbWirelessUsbVolt REAL,
            PcbLed REAL,
            SleepCurr_Spec_ID INTEGER,
            pcbPC TEXT,
            PcbMaxIrPwr REAL,
            PRIMARY KEY (SNumber, PcbStartTime),
            FOREIGN KEY (SNumber) REFERENCES T_MASTER_DATA (SNumber)
        );
    """)

    # 6. T_ITEM_SEMI
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS T_ITEM_SEMI (
            SNumber TEXT, 
            SemiAssyStartTime TEXT, 
            SemiAssyStopTime TEXT, 
            SemiAssyPass TEXT, 
            SemiAssyBatVolt REAL, 
            SemiAssySolarVolt REAL, 
            BatVolt_Spec_ID INTEGER,
            semiPC TEXT,
            SemiAssyMaxBatVolt REAL,
            PRIMARY KEY (SNumber, SemiAssyStartTime),
            FOREIGN KEY (SNumber) REFERENCES T_MASTER_DATA (SNumber)
        );
    """)
    
    # 7. T_ITEM_FW (Pass ì»¬ëŸ¼ ì¶”ê°€)
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS T_ITEM_FW (
            SNumber TEXT, FwStamp TEXT, FwPC TEXT, FwWrMAC TEXT, FwFile TEXT, FwPass TEXT,
            PRIMARY KEY (SNumber, FwStamp),
            FOREIGN KEY (SNumber) REFERENCES T_MASTER_DATA (SNumber)
        );
    """)
    
    # âœ… ê¸°ì¡´ í…Œì´ë¸”ì— FwPass ì»¬ëŸ¼ ì¶”ê°€ (ì—†ìœ¼ë©´)
    try:
        cursor.execute("SELECT FwPass FROM T_ITEM_FW LIMIT 1")
    except:
        try:
            cursor.execute("ALTER TABLE T_ITEM_FW ADD COLUMN FwPass TEXT")
            conn.commit()
            print("âœ… T_ITEM_FWì— FwPass ì»¬ëŸ¼ ì¶”ê°€")
        except Exception as e:
            print(f"âš ï¸ FwPass ì»¬ëŸ¼ ì¶”ê°€ ì‹¤íŒ¨: {e}")
    
    # 8. T_ITEM_RFTX (Pass ì»¬ëŸ¼ ì¶”ê°€)
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS T_ITEM_RFTX (
            SNumber TEXT, RfTxStamp TEXT, RfTxPC TEXT, RfTxPower REAL, RfTxModul REAL, RfTxCFOD REAL, RfTxPass TEXT,
            PRIMARY KEY (SNumber, RfTxStamp),
            FOREIGN KEY (SNumber) REFERENCES T_MASTER_DATA (SNumber)
        );
    """)
    
    # âœ… ê¸°ì¡´ í…Œì´ë¸”ì— RfTxPass ì»¬ëŸ¼ ì¶”ê°€ (ì—†ìœ¼ë©´)
    try:
        cursor.execute("SELECT RfTxPass FROM T_ITEM_RFTX LIMIT 1")
    except:
        try:
            cursor.execute("ALTER TABLE T_ITEM_RFTX ADD COLUMN RfTxPass TEXT")
            conn.commit()
            print("âœ… T_ITEM_RFTXì— RfTxPass ì»¬ëŸ¼ ì¶”ê°€")
        except Exception as e:
            print(f"âš ï¸ RfTxPass ì»¬ëŸ¼ ì¶”ê°€ ì‹¤íŒ¨: {e}")
    
    # 9. T_ITEM_BATADC (Pass ì»¬ëŸ¼ ì¶”ê°€)
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS T_ITEM_BATADC (
            SNumber TEXT, BatadcStamp TEXT, BatadcPC TEXT, BatadcBtVer TEXT, BatadcLevel REAL, 
            BatadcVoiceTh REAL, BatadcVoiceLvl REAL, BatadcRssiRx REAL, BatadcRssiTx REAL, 
            BatadcOffRaw1 REAL, BatadcOnBase REAL, BatadcOnDiff REAL, BatadcSar TEXT, BatadcPass TEXT,
            PRIMARY KEY (SNumber, BatadcStamp),
            FOREIGN KEY (SNumber) REFERENCES T_MASTER_DATA (SNumber)
        );
    """)
    
    # âœ… ê¸°ì¡´ í…Œì´ë¸”ì— BatadcPass ì»¬ëŸ¼ ì¶”ê°€ (ì—†ìœ¼ë©´)
    try:
        cursor.execute("SELECT BatadcPass FROM T_ITEM_BATADC LIMIT 1")
    except:
        try:
            cursor.execute("ALTER TABLE T_ITEM_BATADC ADD COLUMN BatadcPass TEXT")
            conn.commit()
            print("âœ… T_ITEM_BATADCì— BatadcPass ì»¬ëŸ¼ ì¶”ê°€")
        except Exception as e:
            print(f"âš ï¸ BatadcPass ì»¬ëŸ¼ ì¶”ê°€ ì‹¤íŒ¨: {e}")
    
    conn.commit()

def create_or_update_pc_info_streamlit(df_source, conn):
    """T_PC_INFO í…Œì´ë¸”ì„ ìƒì„± ë˜ëŠ” ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤ (APPEND ëª¨ë“œ)"""
    PC_FIELD_MAP = {
        'FwPC': 'FW', 'RfTxPC': 'RFTX', 'BatadcPC': 'BATADC'
    }

    pc_data = []

    # pcbPC: PcbMaxIrPwr ê°’(100, 101, 102, 103)ì„ ê·¸ëŒ€ë¡œ PC_IDë¡œ ì‚¬ìš©
    if 'PcbMaxIrPwr' in df_source.columns:
        df_pcb_values = df_source[['PcbMaxIrPwr']].dropna().drop_duplicates()
        for value in df_pcb_values['PcbMaxIrPwr']:
            if isinstance(value, (int, float, np.float64)):
                pc_id = str(int(value))
                pc_data.append({'PC_ID': pc_id, 'PC_Type': 'PCB'})

    # ê¸°ì¡´ PC ì½”ë“œ ë¡œì§ (FwPC, RfTxPC, BatadcPC)
    for col_name, item_prefix in PC_FIELD_MAP.items():
        if col_name in df_source.columns:
            unique_values = df_source[col_name].dropna().unique()
            for value in unique_values:
                pc_id = str(value)
                pc_type = item_prefix
                pc_data.append({'PC_ID': pc_id, 'PC_Type': pc_type})

    if not pc_data:
        return {'count': 0, 'message': "âš ï¸ T_PC_INFO: ì¶”ê°€í•  PC ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."}

    df_pc_info = pd.DataFrame(pc_data).drop_duplicates(subset=['PC_ID'])
    
    # ê¸°ì¡´ PC_INFO ì¡°íšŒ
    try:
        df_existing_pc = pd.read_sql("SELECT PC_ID FROM T_PC_INFO", conn)
        if len(df_existing_pc) > 0:
            df_new_pc = df_pc_info[~df_pc_info['PC_ID'].isin(df_existing_pc['PC_ID'])]
            if len(df_new_pc) == 0:
                return {'count': 0, 'message': "â„¹ï¸ T_PC_INFO: ì¶”ê°€í•  ì‹ ê·œ PC ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."}
            df_pc_info = df_new_pc
    except:
        pass
    
    df_pc_info.to_sql('T_PC_INFO', conn, if_exists='append', index=False)
    return {'count': len(df_pc_info), 'message': f"âœ… T_PC_INFO: {len(df_pc_info)}í–‰ ì¶”ê°€"}

def extract_and_save_spec_streamlit(df_source, prefix, items_map, spec_table_name, conn):
    """Min/Max ì¶”ì¶œ ë° Spec í…Œì´ë¸” ì €ì¥ (REPLACE ëª¨ë“œ)"""
    all_spec_data = []
    
    for item_name, (min_col_suffix, max_col_suffix) in items_map.items():
        min_col = f'{prefix}{min_col_suffix}{item_name}' 
        max_col = f'{prefix}{max_col_suffix}{item_name}'
        
        if min_col not in df_source.columns or max_col not in df_source.columns:
            continue
            
        df_temp = df_source.dropna(subset=[min_col, max_col]).copy()
        if len(df_temp) == 0:
            continue
            
        unique_specs = df_temp[[min_col, max_col]].drop_duplicates()
        unique_specs['Spec_Key'] = unique_specs.apply(
            lambda row: f"{item_name}_{row[min_col]}_{row[max_col]}", axis=1
        )

        for index, row in unique_specs.iterrows():
            all_spec_data.append({
                'Measure_Item': item_name, 
                'Min_Value': row[min_col], 
                'Max_Value': row[max_col], 
                'Spec_Key': row['Spec_Key'], 
                'Start_Date': '2025-01-01'
            })
            
    if not all_spec_data:
        return {'count': 0, 'message': f"âš ï¸ {spec_table_name}: ì €ì¥í•  ê³ ìœ  Min/Max ì¡°í•©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}

    df_spec = pd.DataFrame(all_spec_data).drop_duplicates(subset=['Spec_Key'])
    df_spec['Spec_ID'] = range(1, len(df_spec) + 1)
    df_spec = df_spec[['Spec_ID', 'Measure_Item', 'Min_Value', 'Max_Value', 'Start_Date', 'Spec_Key']]
    
    df_spec.to_sql(spec_table_name, conn, if_exists='replace', index=False)
    return {'count': len(df_spec), 'message': f"âœ… {spec_table_name}: {len(df_spec)}í–‰ ì €ì¥ (REPLACE)"}

def process_and_save_csv_to_db(df_original, db_file_name):
    """CSV ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ì—¬ DBì— ì €ì¥í•©ë‹ˆë‹¤. (APPEND ëª¨ë“œ)"""
    log_messages = []
    stats = {}
    
    try:
        # 1. DB ì—°ê²° ë° ìŠ¤í‚¤ë§ˆ ìƒì„±
        conn = sqlite3.connect(db_file_name)
        cursor = conn.cursor()
        
        # ìŠ¤í‚¤ë§ˆê°€ ì—†ìœ¼ë©´ ìƒì„±
        create_initial_db_schema(cursor, conn)
        
        cursor.execute("PRAGMA foreign_keys = ON;")
        log_messages.append("âœ… DB ì—°ê²° ë° ìŠ¤í‚¤ë§ˆ í™•ì¸ ì„±ê³µ")
        
        # 2. ë‚ ì§œ ì»¬ëŸ¼ ë³€í™˜
        DATE_COLUMNS_TO_CONVERT = [
            'Stamp', 'SemiAssyStartTime', 'SemiAssyStopTime', 'PcbStartTime', 'PcbStopTime', 
            'FwStamp', 'BatStamp', 'RfTxStamp', 'BatadcStamp'
        ]
        df_original = transform_datetime_columns(df_original, DATE_COLUMNS_TO_CONVERT)
        log_messages.append("âœ… ë‚ ì§œ ì»¬ëŸ¼ ë³€í™˜ ì™„ë£Œ")
        
        # 3. WEEK_NO ê³„ì‚°
        df_original['WEEK_NO'] = df_original['Stamp'].apply(calculate_week_number)
        log_messages.append("âœ… WEEK_NO ê³„ì‚° ì™„ë£Œ")
        
        # 4. pcbPC ì»¬ëŸ¼ ìƒì„±
        if 'PcbMaxIrPwr' in df_original.columns:
            df_original['pcbPC'] = df_original['PcbMaxIrPwr'].apply(
                lambda x: str(int(x)) if pd.notna(x) and isinstance(x, (int, float, np.float64)) else None
            )
            log_messages.append("âœ… pcbPC ì»¬ëŸ¼ ìƒì„± ì™„ë£Œ")
        else:
            df_original['pcbPC'] = None
            log_messages.append("âš ï¸ PcbMaxIrPwr ì»¬ëŸ¼ ì—†ìŒ - pcbPCëŠ” NULL")
        
        # 5. semiPCëŠ” NULL
        df_original['semiPC'] = None
        
        # âœ… 6. T_MASTER_DATA ì €ì¥ (Pass ì œê±° - SNumber, ICount, Stamp, WEEK_NOë§Œ)
        # MASTER_COLUMNS = ['SNumber', 'ICount', 'Stamp', 'WEEK_NO']
        MASTER_COLUMNS = ['SNumber', 'ICount', 'Stamp', 'FwPass', 'BatPass', 'RfTxPass', 'PcbPass', 'SemiAssyPass', 'BatadcPass', 'WEEK_NO']

        df_master = df_original.dropna(subset=['SNumber']).copy()
        df_master = df_master[MASTER_COLUMNS].drop_duplicates(subset=['SNumber'])
        
        # ê¸°ì¡´ SNumber í™•ì¸ í›„ ì‹ ê·œë§Œ ì¶”ê°€
        try:
            existing_snumbers = pd.read_sql("SELECT SNumber FROM T_MASTER_DATA", conn)
        except:
            existing_snumbers = pd.DataFrame(columns=['SNumber'])
        
        df_master_new = df_master[~df_master['SNumber'].isin(existing_snumbers['SNumber'])]
        
        if len(df_master_new) > 0:
            df_master_new.to_sql('T_MASTER_DATA', conn, if_exists='append', index=False)
            stats['master'] = len(df_master_new)
            log_messages.append(f"âœ… T_MASTER_DATA: {len(df_master_new)}í–‰ ì¶”ê°€")
        else:
            stats['master'] = 0
            log_messages.append("â„¹ï¸ T_MASTER_DATA: ì‹ ê·œ ë°ì´í„° ì—†ìŒ")
        
        # âœ… 7. T_ITEM_PCB ì €ì¥ (PcbPass í¬í•¨)
        PCB_VALUE_COLUMNS = ['SNumber', 'PcbStartTime', 'PcbStopTime', 'PcbPass', 'PcbSleepCurr', 'PcbBatVolt', 'PcbIrCurr', 'PcbIrPwr', 'PcbWirelessVolt', 'PcbUsbCurr', 'PcbWirelessUsbVolt', 'PcbLed', 'pcbPC', 'PcbMaxIrPwr']
        
        df_pcb = df_original.dropna(subset=['SNumber', 'PcbStartTime']).copy()
        
        # âœ… PcbPass ì»¬ëŸ¼ ì¶”ê°€ (CSVì—ì„œ ê°€ì ¸ì˜¤ê¸°)
        if 'PcbPass' in df_pcb.columns:
            df_pcb['PcbPass'] = df_pcb['PcbPass'].astype(str).str.lower().replace({'nan': None, 'none': None})
        else:
            df_pcb['PcbPass'] = None
            log_messages.append("âš ï¸ CSVì— PcbPass ì»¬ëŸ¼ ì—†ìŒ - NULLë¡œ ì €ì¥")
        
        if len(df_pcb) > 0:
            try:
                existing_pcb = pd.read_sql("SELECT SNumber, PcbStartTime FROM T_ITEM_PCB", conn)
            except:
                existing_pcb = pd.DataFrame(columns=['SNumber', 'PcbStartTime'])
            
            if len(existing_pcb) > 0:
                df_pcb = df_pcb.merge(existing_pcb, on=['SNumber', 'PcbStartTime'], how='left', indicator=True)
                df_pcb_new = df_pcb[df_pcb['_merge'] == 'left_only'].drop(columns=['_merge'])
            else:
                df_pcb_new = df_pcb
            
            df_pcb_new = df_pcb_new.drop_duplicates(subset=['SNumber', 'PcbStartTime'], keep='first')
            
            if len(df_pcb_new) > 0:
                df_pcb_new[PCB_VALUE_COLUMNS].to_sql('T_ITEM_PCB', conn, if_exists='append', index=False)
                stats['pcb'] = len(df_pcb_new)
                log_messages.append(f"âœ… T_ITEM_PCB: {len(df_pcb_new)}í–‰ ì¶”ê°€")
            else:
                stats['pcb'] = 0
                log_messages.append("â„¹ï¸ T_ITEM_PCB: ì‹ ê·œ ë°ì´í„° ì—†ìŒ")
        else:
            stats['pcb'] = 0
            log_messages.append("âš ï¸ T_ITEM_PCB: ë°ì´í„° ì—†ìŒ")
        
        # âœ… 8. T_ITEM_SEMI ì €ì¥ (SemiAssyPass í¬í•¨)
        SEMI_VALUE_COLUMNS = ['SNumber', 'SemiAssyStartTime', 'SemiAssyStopTime', 'SemiAssyPass', 'SemiAssyBatVolt', 'SemiAssySolarVolt', 'semiPC']
        df_semi = df_original.dropna(subset=['SNumber', 'SemiAssyStartTime']).copy()
        
        # âœ… SemiAssyPass ì»¬ëŸ¼ ì¶”ê°€
        if 'SemiAssyPass' in df_semi.columns:
            df_semi['SemiAssyPass'] = df_semi['SemiAssyPass'].astype(str).str.lower().replace({'nan': None, 'none': None})
        else:
            df_semi['SemiAssyPass'] = None
            log_messages.append("âš ï¸ CSVì— SemiAssyPass ì»¬ëŸ¼ ì—†ìŒ - NULLë¡œ ì €ì¥")
        
        if len(df_semi) > 0:
            try:
                existing_semi = pd.read_sql("SELECT SNumber, SemiAssyStartTime FROM T_ITEM_SEMI", conn)
            except:
                existing_semi = pd.DataFrame(columns=['SNumber', 'SemiAssyStartTime'])
            
            df_semi = df_semi.merge(existing_semi, on=['SNumber', 'SemiAssyStartTime'], how='left', indicator=True)
            df_semi_new = df_semi[df_semi['_merge'] == 'left_only'].drop(columns=['_merge'])
            
            if len(df_semi_new) > 0:
                df_semi_new[SEMI_VALUE_COLUMNS].to_sql('T_ITEM_SEMI', conn, if_exists='append', index=False)
                stats['semi'] = len(df_semi_new)
                log_messages.append(f"âœ… T_ITEM_SEMI: {len(df_semi_new)}í–‰ ì¶”ê°€")
            else:
                stats['semi'] = 0
                log_messages.append("â„¹ï¸ T_ITEM_SEMI: ì‹ ê·œ ë°ì´í„° ì—†ìŒ")
        else:
            stats['semi'] = 0
            log_messages.append("âš ï¸ T_ITEM_SEMI: ë°ì´í„° ì—†ìŒ")
        
        # âœ… 9. T_ITEM_FW ì €ì¥ (FwPass í¬í•¨)
        FW_COLUMNS = ['SNumber', 'FwStamp', 'FwPC', 'FwWrMAC', 'FwFile', 'FwPass']
        df_fw = df_original.dropna(subset=['SNumber', 'FwStamp']).copy()
        
        if 'FwPass' in df_fw.columns:
            df_fw['FwPass'] = df_fw['FwPass'].astype(str).str.lower().replace({'nan': None, 'none': None})
        else:
            df_fw['FwPass'] = None
        
        if len(df_fw) > 0:
            try:
                existing_fw = pd.read_sql("SELECT SNumber, FwStamp FROM T_ITEM_FW", conn)
            except:
                existing_fw = pd.DataFrame(columns=['SNumber', 'FwStamp'])
            
            if len(existing_fw) > 0:
                df_fw = df_fw.merge(existing_fw, on=['SNumber', 'FwStamp'], how='left', indicator=True)
                df_fw_new = df_fw[df_fw['_merge'] == 'left_only'].drop(columns=['_merge'])
            else:
                df_fw_new = df_fw
            
            df_fw_new = df_fw_new.drop_duplicates(subset=['SNumber', 'FwStamp'], keep='first')
            
            if len(df_fw_new) > 0:
                df_fw_new[FW_COLUMNS].to_sql('T_ITEM_FW', conn, if_exists='append', index=False)
                stats['fw'] = len(df_fw_new)
                log_messages.append(f"âœ… T_ITEM_FW: {len(df_fw_new)}í–‰ ì¶”ê°€")
            else:
                stats['fw'] = 0
                log_messages.append("â„¹ï¸ T_ITEM_FW: ì‹ ê·œ ë°ì´í„° ì—†ìŒ")
        else:
            stats['fw'] = 0
            log_messages.append("âš ï¸ T_ITEM_FW: ë°ì´í„° ì—†ìŒ")
        
        # âœ… 10. T_ITEM_RFTX ì €ì¥ (RfTxPass í¬í•¨)
        RFTX_COLUMNS = ['SNumber', 'RfTxStamp', 'RfTxPC', 'RfTxPower', 'RfTxModul', 'RfTxCFOD', 'RfTxPass']
        df_rftx = df_original.dropna(subset=['SNumber', 'RfTxStamp']).copy()
        
        if 'RfTxPass' in df_rftx.columns:
            df_rftx['RfTxPass'] = df_rftx['RfTxPass'].astype(str).str.lower().replace({'nan': None, 'none': None})
        else:
            df_rftx['RfTxPass'] = None
        
        if len(df_rftx) > 0:
            try:
                existing_rftx = pd.read_sql("SELECT SNumber, RfTxStamp FROM T_ITEM_RFTX", conn)
            except:
                existing_rftx = pd.DataFrame(columns=['SNumber', 'RfTxStamp'])
            
            if len(existing_rftx) > 0:
                df_rftx = df_rftx.merge(existing_rftx, on=['SNumber', 'RfTxStamp'], how='left', indicator=True)
                df_rftx_new = df_rftx[df_rftx['_merge'] == 'left_only'].drop(columns=['_merge'])
            else:
                df_rftx_new = df_rftx
            
            df_rftx_new = df_rftx_new.drop_duplicates(subset=['SNumber', 'RfTxStamp'], keep='first')
            
            if len(df_rftx_new) > 0:
                df_rftx_new[RFTX_COLUMNS].to_sql('T_ITEM_RFTX', conn, if_exists='append', index=False)
                stats['rftx'] = len(df_rftx_new)
                log_messages.append(f"âœ… T_ITEM_RFTX: {len(df_rftx_new)}í–‰ ì¶”ê°€")
            else:
                stats['rftx'] = 0
                log_messages.append("â„¹ï¸ T_ITEM_RFTX: ì‹ ê·œ ë°ì´í„° ì—†ìŒ")
        else:
            stats['rftx'] = 0
            log_messages.append("âš ï¸ T_ITEM_RFTX: ë°ì´í„° ì—†ìŒ")
        
        # âœ… 11. T_ITEM_BATADC ì €ì¥ (BatadcPass í¬í•¨)
        BATADC_COLUMNS = ['SNumber', 'BatadcStamp', 'BatadcPC', 'BatadcBtVer', 'BatadcLevel', 'BatadcVoiceTh', 'BatadcVoiceLvl', 'BatadcRssiRx', 'BatadcRssiTx', 'BatadcOffRaw1', 'BatadcOnBase', 'BatadcOnDiff', 'BatadcSar', 'BatadcPass']
        df_batadc = df_original.dropna(subset=['SNumber', 'BatadcStamp']).copy()
        
        if 'BatadcPass' in df_batadc.columns:
            df_batadc['BatadcPass'] = df_batadc['BatadcPass'].astype(str).str.lower().replace({'nan': None, 'none': None})
        else:
            df_batadc['BatadcPass'] = None
        
        if len(df_batadc) > 0:
            try:
                existing_batadc = pd.read_sql("SELECT SNumber, BatadcStamp FROM T_ITEM_BATADC", conn)
            except:
                existing_batadc = pd.DataFrame(columns=['SNumber', 'BatadcStamp'])
            
            if len(existing_batadc) > 0:
                df_batadc = df_batadc.merge(existing_batadc, on=['SNumber', 'BatadcStamp'], how='left', indicator=True)
                df_batadc_new = df_batadc[df_batadc['_merge'] == 'left_only'].drop(columns=['_merge'])
            else:
                df_batadc_new = df_batadc
            
            df_batadc_new = df_batadc_new.drop_duplicates(subset=['SNumber', 'BatadcStamp'], keep='first')
            
            if len(df_batadc_new) > 0:
                df_batadc_new[BATADC_COLUMNS].to_sql('T_ITEM_BATADC', conn, if_exists='append', index=False)
                stats['batadc'] = len(df_batadc_new)
                log_messages.append(f"âœ… T_ITEM_BATADC: {len(df_batadc_new)}í–‰ ì¶”ê°€")
            else:
                stats['batadc'] = 0
                log_messages.append("â„¹ï¸ T_ITEM_BATADC: ì‹ ê·œ ë°ì´í„° ì—†ìŒ")
        else:
            stats['batadc'] = 0
            log_messages.append("âš ï¸ T_ITEM_BATADC: ë°ì´í„° ì—†ìŒ")
        
        # 12. T_PC_INFO ì €ì¥
        log_messages.append("\nğŸ“‹ T_PC_INFO í…Œì´ë¸” ìƒì„±/ì—…ë°ì´íŠ¸ ì‹œì‘...")
        pc_info_result = create_or_update_pc_info_streamlit(df_original, conn)
        stats['pc_info'] = pc_info_result['count']
        log_messages.append(pc_info_result['message'])
        
        # 13. T_SPEC_PCB ì €ì¥
        PCB_ITEMS_MAP = {
            'SleepCurr': ('Min', 'Max'), 
            'BatVolt': ('Min', 'Max'), 
            'IrCurr': ('Min', 'Max'), 
            'IrPwr': ('Min', 'Max'), 
            'WirelessVolt': ('Min', 'Max'), 
            'UsbCurr': ('Min', 'Max'), 
            'WirelessUsbVolt': ('Min', 'Max'), 
            'Led': ('Min', 'Max')
        }
        spec_pcb_result = extract_and_save_spec_streamlit(df_original, 'Pcb', PCB_ITEMS_MAP, 'T_SPEC_PCB', conn)
        stats['spec_pcb'] = spec_pcb_result['count']
        log_messages.append(spec_pcb_result['message'])
        
        # 14. T_SPEC_SEMI ì €ì¥
        SEMI_ITEMS_MAP = {
            'BatVolt': ('Min', 'Max'), 
            'SolarVolt': ('Min', 'Max')
        }
        spec_semi_result = extract_and_save_spec_streamlit(df_original, 'SemiAssy', SEMI_ITEMS_MAP, 'T_SPEC_SEMI', conn)
        stats['spec_semi'] = spec_semi_result['count']
        log_messages.append(spec_semi_result['message'])
        
        conn.commit()
        conn.close()
        log_messages.append("\nâœ… DB ì €ì¥ ì™„ë£Œ")
        
        return {
            'success': True,
            'stats': stats,
            'log': '\n'.join(log_messages)
        }
        
    except Exception as e:
        return {
            'success': False,
            'error': str(e),
            'log': '\n'.join(log_messages)
        }

# ==========================================================
# 1. í•µì‹¬ DB ë° ì¿¼ë¦¬ ì •ì˜ í•¨ìˆ˜
# ==========================================================

def get_db_connection(db_name):
    """DB ì—°ê²°ì„ ìƒˆë¡œ ì—´ì–´ ë°˜í™˜í•©ë‹ˆë‹¤ (ìŠ¤ë ˆë“œ ì˜¤ë¥˜ ë°©ì§€)."""
    if not os.path.exists(db_name):
        return None  # DB íŒŒì¼ ì—†ìŒì„ ë‚˜íƒ€ëƒ„
    # âš ï¸ ìŠ¤ë ˆë”© ë¬¸ì œ í•´ê²°: ì—°ê²° ê°ì²´ëŠ” ìŠ¤ë ˆë“œ ë‚´ì—ì„œ ìƒì„±ë˜ì–´ì•¼ í•¨
    return sqlite3.connect(db_name)

@st.cache_data
def get_pc_info_list(_conn): 
    """T_PC_INFO í…Œì´ë¸”ì—ì„œ PC_ID ëª©ë¡ì„ ë¡œë“œí•˜ì—¬ ìºì‹±í•©ë‹ˆë‹¤."""
    try:
        df_pc = pd.read_sql_query("SELECT PC_ID FROM T_PC_INFO ORDER BY PC_ID", _conn)
        pc_list = df_pc['PC_ID'].tolist()
        return ['ì „ì²´'] + pc_list
    except Exception as e:
        # T_PC_INFOê°€ ì—†ìœ¼ë©´ T_MASTER_DATAì—ì„œ ì¶”ì¶œ
        try:
            df_pc = pd.read_sql_query("SELECT DISTINCT PC_ID FROM T_MASTER_DATA WHERE PC_ID IS NOT NULL ORDER BY PC_ID", _conn)
            pc_list = df_pc['PC_ID'].tolist()
            return ['ì „ì²´'] + pc_list
        except:
            st.warning(f"âš ï¸ PC ëª©ë¡ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            return ['ì „ì²´']



def get_query_and_columns(item_key, date_col, pc_id):
    """SQL ì¿¼ë¦¬ í…œí”Œë¦¿ì„ ìƒì„±í•˜ê³  ë§ˆìŠ¤í„° íŒ¨ìŠ¤ í•„ë“œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤. (T_ITEM í…Œì´ë¸” ì‚¬ìš©)"""
    item_key = item_key.lower()
    
    # âœ…âœ…âœ… FW ì¿¼ë¦¬ (677~692ì¤„)
    if item_key == 'fw':
        fw_pc_filter = ""
        if pc_id and pc_id != 'ì „ì²´':
            fw_pc_filter = f" AND T1.FwPC = '{pc_id.replace(chr(39), chr(39)+chr(39))}'"
        
        query_template = f"""
        SELECT T1.SNumber, T1.{date_col} AS StartTime, 'FileCheck' AS Measure_Item, T1.FwFile AS Test_Value, 
               NULL AS MinLimit, NULL AS MaxLimit,
            CASE 
                WHEN T1.FwPass = 'o' OR T1.FwPass = 'O' THEN 'Pass'
                WHEN T1.FwPass = 'x' OR T1.FwPass = 'X' THEN 'ë¯¸ë‹¬'
                WHEN T1.FwPass IS NULL OR T1.FwPass = '' OR T1.FwPass = 'None' OR T1.FwPass = 'nan' THEN 'ì œì™¸'
                ELSE 'ì œì™¸'
            END AS Spec_Result_Detail
        FROM T_ITEM_FW AS T1
        WHERE T1.{date_col} BETWEEN ? AND ? AND T1.FwFile LIKE ? {fw_pc_filter} LIMIT ?;
        """
        master_pass_field = 'FwPass'
        return query_template, master_pass_field

    # âœ…âœ…âœ… RFTX ì¿¼ë¦¬ (694~712ì¤„)
    elif item_key == 'rftx':
        rftx_pc_filter = ""
        if pc_id and pc_id != 'ì „ì²´':
            rftx_pc_filter = f" AND T1.RfTxPC = '{pc_id.replace(chr(39), chr(39)+chr(39))}'"
        
        query_template = f"""
        SELECT U.SNumber, U.{date_col} AS StartTime, U.Measure_Item, U.Test_Value, 
               NULL AS MinLimit, NULL AS MaxLimit,
            CASE 
                WHEN U.RfTxPass = 'o' OR U.RfTxPass = 'O' THEN 'Pass'
                WHEN U.RfTxPass = 'x' OR U.RfTxPass = 'X' THEN 'ë¯¸ë‹¬'
                WHEN U.RfTxPass IS NULL OR U.RfTxPass = '' OR U.RfTxPass = 'None' OR U.RfTxPass = 'nan' THEN 'ì œì™¸'
                ELSE 'ì œì™¸'
            END AS Spec_Result_Detail
        FROM (
            SELECT T1.SNumber, T1.{date_col}, T1.RfTxPower AS Test_Value, 'Power' AS Measure_Item, T1.RfTxPass FROM T_ITEM_RFTX AS T1 WHERE 1=1 {rftx_pc_filter}
            UNION ALL SELECT T1.SNumber, T1.{date_col}, T1.RfTxModul AS Test_Value, 'Modul' AS Measure_Item, T1.RfTxPass FROM T_ITEM_RFTX AS T1 WHERE 1=1 {rftx_pc_filter}
            UNION ALL SELECT T1.SNumber, T1.{date_col}, T1.RfTxCFOD AS Test_Value, 'CFOD' AS Measure_Item, T1.RfTxPass FROM T_ITEM_RFTX AS T1 WHERE 1=1 {rftx_pc_filter}
        ) AS U
        WHERE U.{date_col} BETWEEN ? AND ? AND U.Measure_Item LIKE ? LIMIT ?;
        """
        master_pass_field = 'RfTxPass'
        return query_template, master_pass_field

    # âœ…âœ…âœ… BATADC ì¿¼ë¦¬ (714~733ì¤„)
    elif item_key == 'batadc':
        batadc_pc_filter = ""
        if pc_id and pc_id != 'ì „ì²´':
            batadc_pc_filter = f" AND T1.BatadcPC = '{pc_id.replace(chr(39), chr(39)+chr(39))}'"
        
        query_template = f"""
        SELECT U.SNumber, U.{date_col} AS StartTime, U.Measure_Item, U.Test_Value, 
               NULL AS MinLimit, NULL AS MaxLimit,
            CASE 
                WHEN U.BatadcPass = 'o' OR U.BatadcPass = 'O' THEN 'Pass'
                WHEN U.BatadcPass = 'x' OR U.BatadcPass = 'X' THEN 'ë¯¸ë‹¬'
                WHEN U.BatadcPass IS NULL OR U.BatadcPass = '' OR U.BatadcPass = 'None' OR U.BatadcPass = 'nan' THEN 'ì œì™¸'
                ELSE 'ì œì™¸'
            END AS Spec_Result_Detail
        FROM (
            SELECT T1.SNumber, T1.{date_col}, T1.BatadcLevel AS Test_Value, 'Level' AS Measure_Item, T1.BatadcPass FROM T_ITEM_BATADC AS T1 WHERE 1=1 {batadc_pc_filter}
            UNION ALL SELECT T1.SNumber, T1.{date_col}, T1.BatadcVoiceTh AS Test_Value, 'VoiceTh' AS Measure_Item, T1.BatadcPass FROM T_ITEM_BATADC AS T1 WHERE 1=1 {batadc_pc_filter}
        ) AS U
        WHERE U.{date_col} BETWEEN ? AND ? AND U.Measure_Item LIKE ? LIMIT ?;
        """
        master_pass_field = 'BatadcPass'
        return query_template, master_pass_field

    # âœ…âœ…âœ… SEMI ì¿¼ë¦¬ (735~756ì¤„)
    elif item_key == 'semi':
        query_template = f"""
        SELECT U.SNumber, U.{date_col} AS StartTime, U.Measure_Item, U.Test_Value, 
               S.Min_Value AS MinLimit, S.Max_Value AS MaxLimit,
            CASE 
                WHEN U.SemiAssyPass = 'o' OR U.SemiAssyPass = 'O' THEN 'Pass'
                WHEN U.SemiAssyPass = 'x' OR U.SemiAssyPass = 'X' THEN (
                    CASE
                        WHEN U.Test_Value IS NULL OR U.Test_Value = 0.0 THEN 'ì œì™¸'
                        WHEN S.Min_Value IS NULL AND S.Max_Value IS NULL THEN 'ì œì™¸'
                        WHEN U.Test_Value < S.Min_Value THEN 'ë¯¸ë‹¬'
                        WHEN U.Test_Value > S.Max_Value THEN 'ì´ˆê³¼'
                        ELSE 'ì œì™¸'
                    END
                )
                WHEN U.SemiAssyPass IS NULL OR U.SemiAssyPass = '' OR U.SemiAssyPass = 'None' OR U.SemiAssyPass = 'nan' THEN 'ì œì™¸'
                ELSE 'ì œì™¸'
            END AS Spec_Result_Detail
        FROM (
            SELECT T1.SNumber, T1.{date_col}, T1.SemiAssyBatVolt AS Test_Value, 'BatVolt' AS Measure_Item, T1.SemiAssyPass FROM T_ITEM_SEMI AS T1
            UNION ALL SELECT T1.SNumber, T1.{date_col}, T1.SemiAssySolarVolt AS Test_Value, 'SolarVolt' AS Measure_Item, T1.SemiAssyPass FROM T_ITEM_SEMI AS T1
        ) AS U
        LEFT JOIN T_SPEC_SEMI AS S ON U.Measure_Item = S.Measure_Item
        WHERE U.{date_col} BETWEEN ? AND ? AND U.Measure_Item LIKE ? LIMIT ?;
        """
        master_pass_field = 'SemiAssyPass'
        return query_template, master_pass_field
        
    # âœ…âœ…âœ… PCB ì¿¼ë¦¬ (758~795ì¤„)
    elif item_key == 'pcb':
        pcb_pc_filter = ""
        if pc_id and pc_id != 'ì „ì²´':
            pcb_pc_filter = f" WHERE T1.pcbPC = '{pc_id.replace(chr(39), chr(39)+chr(39))}'"
        
        query_template = f"""
        SELECT 
            U.SNumber, U.{date_col} AS StartTime, U.Measure_Item, U.Test_Value, 
            S.Min_Value AS MinLimit, S.Max_Value AS MaxLimit,
            CASE 
                WHEN U.PcbPass = 'o' OR U.PcbPass = 'O' THEN 'Pass'
                WHEN U.PcbPass = 'x' OR U.PcbPass = 'X' THEN (
                    CASE
                        WHEN U.Test_Value IS NULL OR U.Test_Value = 0.0 THEN 'ì œì™¸'
                        WHEN S.Min_Value IS NULL AND S.Max_Value IS NULL THEN 'ì œì™¸'
                        WHEN U.Test_Value < S.Min_Value THEN 'ë¯¸ë‹¬'
                        WHEN U.Test_Value > S.Max_Value THEN 'ì´ˆê³¼'
                        ELSE 'ì œì™¸'
                    END
                )
                WHEN U.PcbPass IS NULL OR U.PcbPass = '' OR U.PcbPass = 'None' OR U.PcbPass = 'nan' THEN 'ì œì™¸'
                ELSE 'ì œì™¸'
            END AS Spec_Result_Detail
        FROM (
            SELECT T1.SNumber, T1.{date_col}, T1.PcbSleepCurr AS Test_Value, 'SleepCurr' AS Measure_Item, T1.SleepCurr_Spec_ID AS Spec_ID, T1.PcbPass FROM T_ITEM_PCB AS T1{pcb_pc_filter}
            UNION ALL SELECT T1.SNumber, T1.{date_col}, T1.PcbBatVolt AS Test_Value, 'BatVolt' AS Measure_Item, NULL AS Spec_ID, T1.PcbPass FROM T_ITEM_PCB AS T1{pcb_pc_filter}
            UNION ALL SELECT T1.SNumber, T1.{date_col}, T1.PcbIrCurr AS Test_Value, 'IrCurr' AS Measure_Item, NULL AS Spec_ID, T1.PcbPass FROM T_ITEM_PCB AS T1{pcb_pc_filter}
            UNION ALL SELECT T1.SNumber, T1.{date_col}, T1.PcbIrPwr AS Test_Value, 'IrPwr' AS Measure_Item, NULL AS Spec_ID, T1.PcbPass FROM T_ITEM_PCB AS T1{pcb_pc_filter}
            UNION ALL SELECT T1.SNumber, T1.{date_col}, T1.PcbWirelessVolt AS Test_Value, 'WirelessVolt' AS Measure_Item, NULL AS Spec_ID, T1.PcbPass FROM T_ITEM_PCB AS T1{pcb_pc_filter}
            UNION ALL SELECT T1.SNumber, T1.{date_col}, T1.PcbUsbCurr AS Test_Value, 'UsbCurr' AS Measure_Item, NULL AS Spec_ID, T1.PcbPass FROM T_ITEM_PCB AS T1{pcb_pc_filter}
            UNION ALL SELECT T1.SNumber, T1.{date_col}, T1.PcbWirelessUsbVolt AS Test_Value, 'WirelessUsbVolt' AS Measure_Item, NULL AS Spec_ID, T1.PcbPass FROM T_ITEM_PCB AS T1{pcb_pc_filter}
            UNION ALL SELECT T1.SNumber, T1.{date_col}, T1.PcbLed AS Test_Value, 'Led' AS Measure_Item, NULL AS Spec_ID, T1.PcbPass FROM T_ITEM_PCB AS T1{pcb_pc_filter}
        ) AS U
        LEFT JOIN T_SPEC_PCB AS S 
            ON (U.Spec_ID IS NOT NULL AND U.Spec_ID = S.Spec_ID AND U.Measure_Item = S.Measure_Item)
            OR (U.Spec_ID IS NULL AND U.Measure_Item = S.Measure_Item)
        WHERE 
             U.{date_col} BETWEEN ? AND ?
             AND U.Measure_Item LIKE ?
        LIMIT ?;
        """
        master_pass_field = 'PcbPass'
        return query_template, master_pass_field

    else:
        raise ValueError(f"ì§€ì›ë˜ì§€ ì•ŠëŠ” í•­ëª©: '{item_key}'")



# ----------------- Pandas ìŠ¤íƒ€ì¼ë§ í•¨ìˆ˜ (ë¶ˆëŸ‰ ê°•ì¡°) -----------------
def style_df_failure(df):
    """Pandas DataFrameì—ì„œ 'ë¯¸ë‹¬'/'ì´ˆê³¼'/'ì œì™¸' ê²°ê³¼ë¥¼ ì‹œê°ì ìœ¼ë¡œ ê°•ì¡°í•©ë‹ˆë‹¤."""
    def highlight_failure(val):
        if isinstance(val, str):
            if 'ì´ˆê³¼' in val or 'ë¯¸ë‹¬' in val or val.lower() == 'x':
                return 'background-color: #ffcccc; color: #cc0000' 
            elif 'ì œì™¸' in val:
                return 'background-color: #e0e0e0; color: #555555'
            elif val.lower() == 'o' or val.lower() == 'pass':
                return 'background-color: #ccffcc'
        return ''
    styled_df = df.style.applymap(highlight_failure)
    return styled_df


# ==========================================================
# ìƒˆë¡œ ì¶”ê°€: ë¶ˆëŸ‰ ìœ í˜•ë³„ SNumber ì¡°íšŒ í•¨ìˆ˜
# ==========================================================

# def show_snumbers_by_defect_type(category_1st, category_2nd, analysis_params):
#     """ë¶ˆëŸ‰ ìœ í˜•(1ì°¨/2ì°¨)ì— ë”°ë¼ í•´ë‹¹í•˜ëŠ” SNumber ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤."""
    
#     st.subheader(f"ğŸ“‹ ì¡°íšŒ ê²°ê³¼: {category_1st} â†’ {category_2nd}")
    
#     conn = None
#     try:
#         # ë¶„ì„ íŒŒë¼ë¯¸í„° ê°€ì ¸ì˜¤ê¸°
#         start_date = analysis_params['start']
#         end_date = analysis_params['end']
#         item = analysis_params['item']
#         limit = analysis_params['limit']
#         pc_id = analysis_params['pc_id']
#         measure_item_filter = analysis_params.get('measure_item_filter', 'ì „ì²´')
        
#         item_key = item.lower()
#         start_date_str = start_date.strftime('%Y-%m-%d 00:00:00')
#         end_date_str = end_date.strftime('%Y-%m-%d 23:59:59')
#         date_col = DATE_COLUMN_MAP.get(item_key, 'Stamp')
        
#         st.info(f"ğŸ“Š ì¡°ê±´: {start_date.strftime('%Y-%m-%d')} ~ {end_date.strftime('%Y-%m-%d')} | {item.upper()} | PC: {pc_id} | ìœ í˜•: {measure_item_filter}")
        
#         conn = get_db_connection(DB_FILE_NAME)
        
#         # âœ… get_query_and_columns ì‚¬ìš© (T_ITEM í…Œì´ë¸” ê¸°ë°˜)
#         SQL_STEP1_WITH_PC, master_pass_field = get_query_and_columns(item_key, date_col, pc_id)
        
#         item_filter = '%%'
#         params_step1 = (start_date_str, end_date_str, item_filter, limit)
        
#         with st.spinner("ë°ì´í„° ì¶”ì¶œ ì¤‘..."):
#             df_filtered_all = pd.read_sql_query(SQL_STEP1_WITH_PC, conn, params=params_step1)
            
#             # âœ… measure_item_filter ì ìš©
#             if measure_item_filter != 'ì „ì²´':
#                 before_filter = len(df_filtered_all)
#                 df_filtered_all = df_filtered_all[df_filtered_all['Measure_Item'] == measure_item_filter]
#                 after_filter = len(df_filtered_all)
#                 st.info(f"âœ… ìœ í˜• í•„í„°ë§: {before_filter}ê±´ â†’ {after_filter}ê±´ (ìœ í˜•: {measure_item_filter})")
        
#         if df_filtered_all.empty:
#             st.warning("âš ï¸ í•´ë‹¹ ì¡°ê±´ì— ë§ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
#             return
        
#         # âœ… ë°ì´í„° ì²˜ë¦¬ (run_analysisì™€ ë™ì¼)
#         df_filtered_all['Date_Only'] = df_filtered_all['StartTime'].str[:10]
#         df_final = df_filtered_all.copy()
        
#         # âœ… SNumberë³„ Pass ì—¬ë¶€ í™•ì¸
#         snumber_pass_status = df_final[df_final['Spec_Result_Detail'] == 'Pass'].groupby('SNumber').size().reset_index(name='PassCount')
#         snumber_pass_status['Has_Pass'] = snumber_pass_status['PassCount'] > 0
#         df_final = pd.merge(df_final, snumber_pass_status[['SNumber', 'Has_Pass']], on='SNumber', how='left').fillna({'Has_Pass': False})
        
#         # âœ… SNumberë³„ ê°€ì„±/ì§„ì„± ë¶„ë¥˜
#         snumber_classification = df_final.groupby('SNumber').agg({
#             'Has_Pass': 'first'
#         }).reset_index()
        
#         snumber_classification['SNumber_Category'] = snumber_classification['Has_Pass'].apply(
#             lambda x: 'ê°€ì„±ë¶ˆëŸ‰' if x else 'ì§„ì„±ë¶ˆëŸ‰'
#         )
        
#         df_final = pd.merge(df_final, snumber_classification[['SNumber', 'SNumber_Category']], on='SNumber', how='left')
        
#         # âœ… Final_Failure_Category ê²°ì •
#         def classify_failure_final(row):
#             detail = row['Spec_Result_Detail']
            
#             if detail == 'Pass':
#                 return 'Pass'
#             elif detail in ['ë¯¸ë‹¬', 'ì´ˆê³¼', 'ì œì™¸']:
#                 return row['SNumber_Category']
#             else:
#                 return detail
        
#         df_final['Final_Failure_Category'] = df_final.apply(classify_failure_final, axis=1)
        
#         # âœ… í•„í„°ë§ (ìµœì¢… 1ì°¨/2ì°¨ ë¶„ë¥˜ ì¡°ê±´ì— ë§ëŠ” í–‰ë§Œ ë‚¨ê¹€)
#         df_filtered = df_final[
#             (df_final['Final_Failure_Category'] == category_1st) &
#             (df_final['Spec_Result_Detail'] == category_2nd)
#         ].copy()
        
#         if df_filtered.empty:
#             st.warning(f"âš ï¸ '{category_1st} â†’ {category_2nd}' ì¡°ê±´ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
#             return

#         # âœ… í†µê³„ ì •ë³´ í‘œì‹œ
#         total_records = len(df_filtered)
#         unique_snumbers = df_filtered['SNumber'].nunique()
        
#         col1, col2 = st.columns(2)
#         with col1:
#             st.metric("ğŸ“Š ì „ì²´ ì¸¡ì • ê±´ìˆ˜", f"{total_records:,}ê±´")
#         with col2:
#             st.metric("ğŸ”¢ ê³ ìœ  SNumber ê°œìˆ˜", f"{unique_snumbers:,}ê°œ")
        
#         st.markdown("---")
        
#         # ë‚ ì§œë³„ë¡œ ê·¸ë£¹í™”í•˜ì—¬ í‘œì‹œ
#         df_filtered['Date_Only'] = df_filtered['StartTime'].str[:10]
        
#         for date in sorted(df_filtered['Date_Only'].unique()):
#             df_date = df_filtered[df_filtered['Date_Only'] == date]
#             records_on_date = len(df_date)
#             snumbers_on_date = df_date['SNumber'].unique().tolist()
#             unique_count = len(snumbers_on_date)
            
#             with st.expander(f"ğŸ“… {date} | ì¸¡ì • {records_on_date:,}ê±´ / ê³ ìœ  SNumber {unique_count:,}ê°œ", expanded=False):
#                 # ìƒì„¸ ì •ë³´ í…Œì´ë¸” ìƒì„±
#                 df_date_detailed = df_date.copy()
                
#                 # âœ… ìˆ˜ì •: DataFrameì— ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ ì‚¬ìš©
#                 # ë¨¼ì € ì–´ë–¤ ì»¬ëŸ¼ì´ ìˆëŠ”ì§€ í™•ì¸
#                 available_columns = df_date_detailed.columns.tolist()
                
#                 # í‘œì‹œí•  ì»¬ëŸ¼ ì„ íƒ (ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ)
#                 display_columns = {}
                
#                 # ê¸°ë³¸ ì»¬ëŸ¼ (í•­ìƒ ìˆìŒ)
#                 if 'SNumber' in available_columns:
#                     display_columns['SNumber'] = 'SNumber'
#                 if 'StartTime' in available_columns:
#                     display_columns['StartTime'] = 'Stamp'
#                 if 'Measure_Item' in available_columns:
#                     display_columns['Measure_Item'] = 'ì¸¡ì •í•­ëª©'
#                 if 'Test_Value' in available_columns:
#                     display_columns['Test_Value'] = 'ì¸¡ì •ê°’'
#                 if 'MinLimit' in available_columns:
#                     display_columns['MinLimit'] = 'Min (ê¸°ì¤€)'
#                 if 'MaxLimit' in available_columns:
#                     display_columns['MaxLimit'] = 'Max (ê¸°ì¤€)'
#                 if 'Spec_Result_Detail' in available_columns:
#                     display_columns['Spec_Result_Detail'] = 'íŒì •ê²°ê³¼'
#                 if 'Final_Failure_Category' in available_columns:
#                     display_columns['Final_Failure_Category'] = 'ê°€ì„±/ì§„ì„±'
#                 if 'SNumber_Category' in available_columns:
#                     display_columns['SNumber_Category'] = 'SNumberë¶„ë¥˜'
                
#                 # âœ… ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ ì„ íƒ
#                 df_display = df_date_detailed[list(display_columns.keys())].rename(columns=display_columns)
                
#                 # ë²ˆí˜¸ ì¶”ê°€
#                 df_display.insert(0, 'ë²ˆí˜¸', range(1, len(df_display) + 1))
                
#                 # ìŠ¤íƒ€ì¼ ì ìš©í•˜ì—¬ í‘œì‹œ
#                 st.dataframe(style_df_failure(df_display), use_container_width=True, hide_index=True, height=400)
                
#                 # ì„ íƒ ê°€ëŠ¥í•œ selectbox ì¶”ê°€
#                 selected_sn = st.selectbox(
#                     f"ìƒì„¸ ì¡°íšŒí•  SNumber ì„ íƒ ({date}):",
#                     snumbers_on_date,
#                     key=f"select_sn_{date}_{category_1st}_{category_2nd}"
#                 )
                
#                 if st.button(f"ìƒì„¸ ì¡°íšŒ", key=f"detail_btn_{date}_{category_1st}_{category_2nd}"):
#                     st.markdown("---")
#                     show_single_snumber_detail(selected_sn, item_key, conn, analysis_params['pc_id'])
    
#     except Exception as e:
#         st.error(f"âŒ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
#         import traceback
#         st.code(traceback.format_exc())
#     finally:
#         if conn:
#             conn.close()
def show_snumbers_by_defect_type(category_1st, category_2nd, analysis_params):
    """ë¶ˆëŸ‰ ìœ í˜•(1ì°¨/2ì°¨)ì— ë”°ë¼ í•´ë‹¹í•˜ëŠ” SNumber ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤."""
    
    st.subheader(f"ğŸ“‹ ì¡°íšŒ ê²°ê³¼: {category_1st} â†’ {category_2nd}")
    
    conn = None
    try:
        # ë¶„ì„ íŒŒë¼ë¯¸í„° ê°€ì ¸ì˜¤ê¸°
        start_date = analysis_params['start']
        end_date = analysis_params['end']
        item = analysis_params['item']
        limit = analysis_params['limit']
        pc_id = analysis_params['pc_id']
        measure_item_filter = analysis_params.get('measure_item_filter', 'ì „ì²´')
        
        item_key = item.lower()
        start_date_str = start_date.strftime('%Y-%m-%d 00:00:00')
        end_date_str = end_date.strftime('%Y-%m-%d 23:59:59')
        date_col = DATE_COLUMN_MAP.get(item_key, 'Stamp')
        
        st.info(f"ğŸ“Š ì¡°ê±´: {start_date.strftime('%Y-%m-%d')} ~ {end_date.strftime('%Y-%m-%d')} | {item.upper()} | PC: {pc_id} | ìœ í˜•: {measure_item_filter}")
        
        conn = get_db_connection(DB_FILE_NAME)
        
        # âœ… get_query_and_columns ì‚¬ìš© (T_ITEM í…Œì´ë¸” ê¸°ë°˜)
        SQL_STEP1_WITH_PC, master_pass_field = get_query_and_columns(item_key, date_col, pc_id)
        
        item_filter = '%%'
        params_step1 = (start_date_str, end_date_str, item_filter, limit)
        
        with st.spinner("ë°ì´í„° ì¶”ì¶œ ì¤‘..."):
            df_filtered_all = pd.read_sql_query(SQL_STEP1_WITH_PC, conn, params=params_step1)
            
            # âœ… measure_item_filter ì ìš©
            if measure_item_filter != 'ì „ì²´':
                before_filter = len(df_filtered_all)
                df_filtered_all = df_filtered_all[df_filtered_all['Measure_Item'] == measure_item_filter]
                after_filter = len(df_filtered_all)
                st.info(f"âœ… ìœ í˜• í•„í„°ë§: {before_filter}ê±´ â†’ {after_filter}ê±´ (ìœ í˜•: {measure_item_filter})")
        
        if df_filtered_all.empty:
            st.warning("âš ï¸ í•´ë‹¹ ì¡°ê±´ì— ë§ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # âœ… ë°ì´í„° ì²˜ë¦¬ (run_analysisì™€ ë™ì¼)
        df_filtered_all['Date_Only'] = df_filtered_all['StartTime'].str[:10]
        df_final = df_filtered_all.copy()
        
        # âœ… SNumberë³„ Pass ì—¬ë¶€ í™•ì¸
        snumber_pass_status = df_final[df_final['Spec_Result_Detail'] == 'Pass'].groupby('SNumber').size().reset_index(name='PassCount')
        snumber_pass_status['Has_Pass'] = snumber_pass_status['PassCount'] > 0
        df_final = pd.merge(df_final, snumber_pass_status[['SNumber', 'Has_Pass']], on='SNumber', how='left').fillna({'Has_Pass': False})
        
        # âœ… SNumberë³„ ê°€ì„±/ì§„ì„± ë¶„ë¥˜
        snumber_classification = df_final.groupby('SNumber').agg({
            'Has_Pass': 'first'
        }).reset_index()
        
        snumber_classification['SNumber_Category'] = snumber_classification['Has_Pass'].apply(
            lambda x: 'ê°€ì„±ë¶ˆëŸ‰' if x else 'ì§„ì„±ë¶ˆëŸ‰'
        )
        
        df_final = pd.merge(df_final, snumber_classification[['SNumber', 'SNumber_Category']], on='SNumber', how='left')
        
        # âœ… Final_Failure_Category ê²°ì •
        def classify_failure_final(row):
            detail = row['Spec_Result_Detail']
            
            if detail == 'Pass':
                return 'Pass'
            elif detail in ['ë¯¸ë‹¬', 'ì´ˆê³¼', 'ì œì™¸']:
                return row['SNumber_Category']
            else:
                return detail
        
        df_final['Final_Failure_Category'] = df_final.apply(classify_failure_final, axis=1)
        
        # âœ… í•„í„°ë§ (ìµœì¢… 1ì°¨/2ì°¨ ë¶„ë¥˜ ì¡°ê±´ì— ë§ëŠ” í–‰ë§Œ ë‚¨ê¹€)
        df_filtered = df_final[
            (df_final['Final_Failure_Category'] == category_1st) &
            (df_final['Spec_Result_Detail'] == category_2nd)
        ].copy()
        
        if df_filtered.empty:
            st.warning(f"âš ï¸ '{category_1st} â†’ {category_2nd}' ì¡°ê±´ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        # âœ… í†µê³„ ì •ë³´ í‘œì‹œ
        total_records = len(df_filtered)
        unique_snumbers = df_filtered['SNumber'].nunique()
        
        col1, col2 = st.columns(2)
        with col1:
            st.metric("ğŸ“Š ì „ì²´ ì¸¡ì • ê±´ìˆ˜", f"{total_records:,}ê±´")
        with col2:
            st.metric("ğŸ”¢ ê³ ìœ  SNumber ê°œìˆ˜", f"{unique_snumbers:,}ê°œ")
        
        st.markdown("---")
        
        # ë‚ ì§œë³„ë¡œ ê·¸ë£¹í™”í•˜ì—¬ í‘œì‹œ
        df_filtered['Date_Only'] = df_filtered['StartTime'].str[:10]
        
        for date in sorted(df_filtered['Date_Only'].unique()):
            df_date = df_filtered[df_filtered['Date_Only'] == date]
            records_on_date = len(df_date)
            snumbers_on_date = df_date['SNumber'].unique().tolist()
            unique_count = len(snumbers_on_date)
            
            with st.expander(f"ğŸ“… {date} | ì¸¡ì • {records_on_date:,}ê±´ / ê³ ìœ  SNumber {unique_count:,}ê°œ", expanded=False):
                # ìƒì„¸ ì •ë³´ í…Œì´ë¸” ìƒì„±
                df_date_detailed = df_date.copy()
                
                # âœ… ìˆ˜ì •: DataFrameì— ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ ì‚¬ìš©
                available_columns = df_date_detailed.columns.tolist()
                
                # í‘œì‹œí•  ì»¬ëŸ¼ ì„ íƒ (ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ)
                display_columns = {}
                
                # ê¸°ë³¸ ì»¬ëŸ¼ (í•­ìƒ ìˆìŒ)
                if 'SNumber' in available_columns:
                    display_columns['SNumber'] = 'SNumber'
                if 'StartTime' in available_columns:
                    display_columns['StartTime'] = 'Stamp'
                if 'Measure_Item' in available_columns:
                    display_columns['Measure_Item'] = 'ì¸¡ì •í•­ëª©'
                if 'Test_Value' in available_columns:
                    display_columns['Test_Value'] = 'ì¸¡ì •ê°’'
                if 'MinLimit' in available_columns:
                    display_columns['MinLimit'] = 'Min (ê¸°ì¤€)'
                if 'MaxLimit' in available_columns:
                    display_columns['MaxLimit'] = 'Max (ê¸°ì¤€)'
                if 'Spec_Result_Detail' in available_columns:
                    display_columns['Spec_Result_Detail'] = 'íŒì •ê²°ê³¼'
                if 'Final_Failure_Category' in available_columns:
                    display_columns['Final_Failure_Category'] = 'ê°€ì„±/ì§„ì„±'
                if 'SNumber_Category' in available_columns:
                    display_columns['SNumber_Category'] = 'SNumberë¶„ë¥˜'
                
                # âœ… ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ ì„ íƒ
                df_display = df_date_detailed[list(display_columns.keys())].rename(columns=display_columns)
                
                # ë²ˆí˜¸ ì¶”ê°€
                df_display.insert(0, 'ë²ˆí˜¸', range(1, len(df_display) + 1))
                
                # ìŠ¤íƒ€ì¼ ì ìš©í•˜ì—¬ í‘œì‹œ
                st.dataframe(style_df_failure(df_display), use_container_width=True, hide_index=True, height=400)
                
                # ì„ íƒ ê°€ëŠ¥í•œ selectbox ì¶”ê°€
                selected_sn = st.selectbox(
                    f"ìƒì„¸ ì¡°íšŒí•  SNumber ì„ íƒ ({date}):",
                    snumbers_on_date,
                    key=f"select_sn_{date}_{category_1st}_{category_2nd}"
                )
                
                if st.button(f"ìƒì„¸ ì¡°íšŒ", key=f"detail_btn_{date}_{category_1st}_{category_2nd}"):
                    st.markdown("---")
                    # âœ… ë‚ ì§œ í•„í„° ì „ë‹¬
                    show_single_snumber_detail(
                        selected_sn, 
                        item_key, 
                        conn, 
                        pc_id=analysis_params['pc_id'],
                        start_date=start_date,  # â† ì¶”ê°€!
                        end_date=end_date       # â† ì¶”ê°€!
                    )
    
    except Exception as e:
        st.error(f"âŒ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        st.code(traceback.format_exc())
    finally:
        if conn:
            conn.close()

# ==========================================================
# ìƒˆë¡œ ì¶”ê°€: SNumber ê²€ìƒ‰ ë° ìƒì„¸ ì¡°íšŒ í•¨ìˆ˜
# ==========================================================
def search_snumber(search_pattern, conn):
    """SNumberë¥¼ íŒ¨í„´ìœ¼ë¡œ ê²€ìƒ‰í•©ë‹ˆë‹¤ (ì™€ì¼ë“œì¹´ë“œ ì§€ì›)."""
    try:
        # % ì™€ì¼ë“œì¹´ë“œ ìë™ ì¶”ê°€
        if '*' in search_pattern:
            search_pattern = search_pattern.replace('*', '%')
        else:
            # *ê°€ ì—†ìœ¼ë©´ ìë™ìœ¼ë¡œ ì–‘ìª½ì— % ì¶”ê°€
            search_pattern = f"%{search_pattern}%"
        
        query = "SELECT DISTINCT SNumber FROM T_MASTER_DATA WHERE SNumber LIKE ? ORDER BY SNumber LIMIT 100"
        df_results = pd.read_sql_query(query, conn, params=(search_pattern,))
        
        return df_results['SNumber'].tolist()
    except Exception as e:
        st.error(f"âŒ SNumber ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        return []


def show_snumber_detail(snumber_input, item_key):
    """SNumber ìƒì„¸ ì¡°íšŒë¥¼ ë…ë¦½ì ìœ¼ë¡œ ìˆ˜í–‰í•©ë‹ˆë‹¤."""
    if not snumber_input:
        st.info("â¬†ï¸ ìœ„ì˜ ì…ë ¥ì°½ì— ì¡°íšŒí•  SNumberë¥¼ ì…ë ¥í•˜ê³  ë²„íŠ¼ì„ ëˆ„ë¥´ì„¸ìš”.")
        st.info("ğŸ’¡ íŒ: ì¼ë¶€ë§Œ ì…ë ¥í•˜ë©´ ìë™ìœ¼ë¡œ ê²€ìƒ‰ë©ë‹ˆë‹¤ (ì˜ˆ: THSR, *9226)")
        return
    
    conn = get_db_connection(DB_FILE_NAME)
    if conn is None: 
        st.stop()

    try:
        # 1. ë¨¼ì € ê²€ìƒ‰ ìˆ˜í–‰
        matching_snumbers = search_snumber(snumber_input, conn)
        
        if not matching_snumbers:
            st.warning(f"âš ï¸ '{snumber_input}' íŒ¨í„´ê³¼ ì¼ì¹˜í•˜ëŠ” SNumberê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # 2. ê²€ìƒ‰ ê²°ê³¼ê°€ ì—¬ëŸ¬ ê°œì¸ ê²½ìš°
        if len(matching_snumbers) > 1:
            st.success(f"ğŸ” ê²€ìƒ‰ ê²°ê³¼: {len(matching_snumbers)}ê±´ ë°œê²¬")
            
            # ê²°ê³¼ ëª©ë¡ì„ DataFrameìœ¼ë¡œ í‘œì‹œ
            df_search_results = pd.DataFrame({
                'ë²ˆí˜¸': range(1, len(matching_snumbers) + 1),
                'SNumber': matching_snumbers
            })
            
            st.dataframe(df_search_results, use_container_width=True, hide_index=True)
            
            # ì„ íƒ ê°€ëŠ¥í•œ selectbox ì¶”ê°€
            st.markdown("---")
            selected_snumber = st.selectbox(
                "ìƒì„¸ ì¡°íšŒí•  SNumber ì„ íƒ:",
                matching_snumbers,
                key="selected_snumber_from_search"
            )
            
            if st.button("ì„ íƒí•œ SNumber ìƒì„¸ ì¡°íšŒ", key="detail_from_selected"):
                # show_single_snumber_detail(selected_snumber, item_key, conn)
                show_single_snumber_detail(selected_snumber, item_key, conn, selected_pc_id)
        
        # 3. ê²€ìƒ‰ ê²°ê³¼ê°€ 1ê°œì¸ ê²½ìš° ë°”ë¡œ ìƒì„¸ ì¡°íšŒ
        else:
            snumber_to_show = matching_snumbers[0]
            st.info(f"âœ… ì¼ì¹˜í•˜ëŠ” SNumber: {snumber_to_show}")
            show_single_snumber_detail(snumber_to_show, item_key, conn, selected_pc_id)
            
    except Exception as e:
        st.error(f"âŒ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    finally:
        conn.close()


def show_single_snumber_detail(snumber, item_key, conn, pc_id=None, start_date=None, end_date=None):
    """ë‹¨ì¼ SNumberì˜ ìƒì„¸ ì •ë³´ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤. (ë‚ ì§œ í•„í„° ì¶”ê°€)"""
    try:
        # âœ… ë‚ ì§œ ì»¬ëŸ¼ ë§¤í•‘
        date_col_map = {
            'fw': 'FwStamp',
            'rftx': 'RfTxStamp',
            'batadc': 'BatadcStamp',
            'pcb': 'PcbStartTime',
            'semi': 'SemiAssyStartTime'
        }
        date_col = date_col_map.get(item_key, 'Stamp')
        
        # T_MASTER_DATA ì „ì²´ ìš”ì•½ (ë‚ ì§œ í•„í„° ì—†ìŒ)
        master_query = "SELECT * FROM T_MASTER_DATA WHERE SNumber = ?"
        df_master = pd.read_sql_query(master_query, conn, params=(snumber,))
        
        if df_master.empty:
            st.warning(f"âš ï¸ SNumber '{snumber}'ì— ëŒ€í•œ ë§ˆìŠ¤í„° ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        st.markdown(f"### âœ… SNumber: `{snumber}` ì „ì²´ ê³µì • ìš”ì•½")
        st.dataframe(df_master.T, use_container_width=True)
        
        # T_ITEM_XXX ìƒì„¸ ì¸¡ì • ë‚´ì—­ ì¡°íšŒ
        item_table_name = f"T_ITEM_{item_key.upper()}"
        
        # âœ… ë‚ ì§œ í•„í„° ì¡°ê±´ ìƒì„±
        date_filter = ""
        params = [snumber]
        
        if start_date and end_date:
            start_date_str = start_date.strftime('%Y-%m-%d 00:00:00')
            end_date_str = end_date.strftime('%Y-%m-%d 23:59:59')
            date_filter = f" AND {date_col} BETWEEN ? AND ?"
            params.extend([start_date_str, end_date_str])
        
        # âœ… PC í•„í„° ì¶”ê°€
        pc_filter = ""
        if pc_id and pc_id != 'ì „ì²´':
            # í’ˆëª©ë³„ PC ì»¬ëŸ¼ëª… í™•ì¸
            pc_column_map = {
                'fw': 'FwPC',
                'rftx': 'RfTxPC',
                'batadc': 'BatadcPC',
                'pcb': 'pcbPC',
                'semi': None  # SEMIëŠ” PC ì—†ìŒ
            }
            
            pc_column = pc_column_map.get(item_key)
            
            if pc_column:
                pc_filter = f" AND {pc_column} = ?"
                params.append(pc_id)
        
        # âœ… ì¿¼ë¦¬ ì‹¤í–‰
        item_query = f"SELECT * FROM {item_table_name} WHERE SNumber = ?{date_filter}{pc_filter} ORDER BY {date_col}"
        df_item = pd.read_sql_query(item_query, conn, params=tuple(params))
        
        if not df_item.empty:
            st.markdown(f"### âœ… {item_key.upper()} ìƒì„¸ ì¸¡ì • ë‚´ì—­ ({item_table_name})")
            
            # âœ… í•„í„° ì •ë³´ í‘œì‹œ
            filter_info = []
            if start_date and end_date:
                filter_info.append(f"ğŸ“… ê¸°ê°„: {start_date.strftime('%Y-%m-%d')} ~ {end_date.strftime('%Y-%m-%d')}")
            if pc_id and pc_id != 'ì „ì²´':
                filter_info.append(f"ğŸ–¥ï¸ PC: {pc_id}")
            
            if filter_info:
                st.info(" | ".join(filter_info))
            
            # âœ… Pass ì»¬ëŸ¼ í†µê³„ (í’ˆëª©ë³„ Pass ì»¬ëŸ¼ëª…)
            pass_col_map = {
                'fw': 'FwPass',
                'rftx': 'RfTxPass',
                'batadc': 'BatadcPass',
                'pcb': 'PcbPass',
                'semi': 'SemiAssyPass'
            }
            pass_col = pass_col_map.get(item_key)
            
            if pass_col and pass_col in df_item.columns:
                # ì¤‘ë³µ ì œê±°: ë™ì¼ Stampì—ì„œ í•˜ë‚˜ì˜ Passë§Œ ì¹´ìš´íŠ¸
                df_unique = df_item.drop_duplicates(subset=[date_col])
                o_count = ((df_unique[pass_col] == 'o') | (df_unique[pass_col] == 'O')).sum()
                x_count = ((df_unique[pass_col] == 'x') | (df_unique[pass_col] == 'X')).sum()
                total_tests = len(df_unique)
                
                st.info(f"ğŸ“Š ì¸¡ì • íšŸìˆ˜: ì´ {total_tests}íšŒ (ê³ ìœ  {date_col} ê¸°ì¤€) | Pass(o): {o_count}íšŒ | Fail(x): {x_count}íšŒ")
                
                # âœ… íŒì • ê²€ì¦
                if o_count > 0:
                    judgment = "ê°€ì„±ë¶ˆëŸ‰"
                    judgment_color = "green"
                    st.success(f"âœ… **ì„ íƒëœ ê¸°ê°„ ë‚´** Passê°€ {o_count}íšŒ ìˆìœ¼ë¯€ë¡œ **ê°€ì„±ë¶ˆëŸ‰**ì´ ë§ìŠµë‹ˆë‹¤.")
                else:
                    judgment = "ì§„ì„±ë¶ˆëŸ‰"
                    judgment_color = "red"
                    st.error(f"âŒ **ì„ íƒëœ ê¸°ê°„ ë‚´** Passê°€ ì—†ìœ¼ë¯€ë¡œ **ì§„ì„±ë¶ˆëŸ‰**ì´ì–´ì•¼ í•©ë‹ˆë‹¤!")
            
            st.dataframe(style_df_failure(df_item), use_container_width=True)
        else:
            st.info(f"ì„ íƒëœ ì¡°ê±´({item_key.upper()})ì— ëŒ€í•œ ìƒì„¸ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤.")
        
    except Exception as e:
        st.error(f"âŒ ìƒì„¸ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        st.code(traceback.format_exc())


# ==========================================================
# STREAMLIT APP ì‹¤í–‰ í•¨ìˆ˜
# ==========================================================

def run_analysis(start_date, end_date, item, limit, pc_id, measure_item_filter='ì „ì²´'):
    """ë°ì´í„° ë¶„ì„ì„ ì‹¤í–‰í•©ë‹ˆë‹¤. (T_ITEM í…Œì´ë¸”ë§Œ ì‚¬ìš©)"""
    
    conn = None
    try:
        item_key = item.lower()
        limit = int(limit)
        
        start_date_str = start_date.strftime('%Y-%m-%d 00:00:00')
        end_date_str = end_date.strftime('%Y-%m-%d 23:59:59')
        date_col = DATE_COLUMN_MAP.get(item_key, 'Stamp') 

        conn = get_db_connection(DB_FILE_NAME) 
        
        # âœ… T_ITEM í…Œì´ë¸”ë§Œ ì‚¬ìš©í•˜ëŠ” ì¿¼ë¦¬
        SQL_STEP1, master_pass_field = get_query_and_columns(item_key, date_col, pc_id) 
        item_filter = '%%'
        params_step1 = (start_date_str, end_date_str, item_filter, limit)
        
        st.info(f"ì¡°íšŒ ê¸°ê°„: **{start_date_str}** ë¶€í„° **{end_date_str}** ê¹Œì§€ | í•­ëª©: **{item.upper()}** | PC: **{pc_id}** | ìœ í˜•: **{measure_item_filter}**")

        # 2. ë°ì´í„° ì¶”ì¶œ
        with st.spinner("DBì—ì„œ ë°ì´í„° ì¶”ì¶œ ë° ë¶„ë¥˜ ì¤‘..."):
            df_filtered_all = pd.read_sql_query(SQL_STEP1, conn, params=params_step1)
            
            # âœ… measure_item_filter ì ìš©
            if measure_item_filter != 'ì „ì²´':
                before_filter = len(df_filtered_all)
                df_filtered_all = df_filtered_all[df_filtered_all['Measure_Item'] == measure_item_filter]
                after_filter = len(df_filtered_all)
                st.info(f"âœ… ìœ í˜• í•„í„°ë§: {before_filter}ê±´ â†’ {after_filter}ê±´ (ìœ í˜•: {measure_item_filter})")

            # âŒ SQL_STEP2 ì™„ì „ ì œê±°! (T_MASTER_DATA ì‚¬ìš© ì•ˆ í•¨)
            
        if df_filtered_all.empty:
            st.warning("âš ï¸ í•´ë‹¹ ê¸°ê°„ì— ì¡°íšŒëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

    except Exception as e:
        st.error(f"âŒ ë°ì´í„° ì¶”ì¶œ ì˜¤ë¥˜: {e}")
        import traceback
        st.code(traceback.format_exc())
        return
    finally:
        if conn:
            conn.close() 

    # âœ…âœ…âœ… 3. ë°ì´í„° ì²˜ë¦¬ ë° ê°€ì„±/ì§„ì„± ë¶„ë¥˜
    
    df_filtered_all['Date_Only'] = df_filtered_all['StartTime'].str[:10]
    df_final = df_filtered_all.copy()
    
    # âœ… SNumberë³„ Pass ì—¬ë¶€ í™•ì¸
    snumber_pass_status = df_final[df_final['Spec_Result_Detail'] == 'Pass'].groupby('SNumber').size().reset_index(name='PassCount')
    snumber_pass_status['Has_Pass'] = snumber_pass_status['PassCount'] > 0
    df_final = pd.merge(df_final, snumber_pass_status[['SNumber', 'Has_Pass']], on='SNumber', how='left').fillna({'Has_Pass': False})
    
    # âœ… SNumberë³„ ê°€ì„±/ì§„ì„± ë¶„ë¥˜
    snumber_classification = df_final.groupby('SNumber').agg({
        'Has_Pass': 'first'
    }).reset_index()
    
    snumber_classification['SNumber_Category'] = snumber_classification['Has_Pass'].apply(
        lambda x: 'ê°€ì„±ë¶ˆëŸ‰' if x else 'ì§„ì„±ë¶ˆëŸ‰'
    )
    
    df_final = pd.merge(df_final, snumber_classification[['SNumber', 'SNumber_Category']], on='SNumber', how='left')
    
    # âœ… ë‚ ì§œë³„ ì§‘ê³„
    unique_dates = sorted(df_final['Date_Only'].unique())
    
    st.subheader(f"ğŸ“ˆ {item.upper()} í•­ëª© | ê¸°ê°„ ({len(unique_dates)}ì¼) ìƒì„¸ ë¶„ì„")

    for date_only in unique_dates:
        df_day = df_final[df_final['Date_Only'] == date_only].copy()

        # âœ… Final_Failure_Category ê²°ì •
        def classify_failure_final(row):
            detail = row['Spec_Result_Detail']
            
            if detail == 'Pass':
                return 'Pass'
            elif detail in ['ë¯¸ë‹¬', 'ì´ˆê³¼', 'ì œì™¸']:
                return row['SNumber_Category']
            else:
                return detail

        df_day['Final_Failure_Category'] = df_day.apply(classify_failure_final, axis=1)

        # ì§‘ê³„ í…Œì´ë¸” ìƒì„±
        df_summary = df_day[df_day['Spec_Result_Detail'].isin(['Pass', 'ë¯¸ë‹¬', 'ì´ˆê³¼', 'ì œì™¸'])].copy()
        
        if not df_summary.empty:
            summary_table = pd.crosstab(
                index=df_summary['Final_Failure_Category'], 
                columns=df_summary['Spec_Result_Detail'], 
                margins=True, 
                margins_name="Total"
            )
            summary_table = summary_table.reindex(
                index=['Pass', 'ê°€ì„±ë¶ˆëŸ‰', 'ì§„ì„±ë¶ˆëŸ‰', 'Total'],
                columns=['Pass', 'ë¯¸ë‹¬', 'ì´ˆê³¼', 'ì œì™¸', 'Total'], 
                fill_value=0
            )
            
            st.markdown(f"#### ğŸ—“ï¸ {date_only} ({len(df_summary)} ê±´)")
            st.dataframe(summary_table, use_container_width=True)

    st.success("âœ”ï¸ ì „ì²´ ê¸°ê°„ ë¶„ì„ ë° í…Œì´ë¸” ì¶œë ¥ ì™„ë£Œ!")

# ==========================================================
# 4. ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
# ==========================================================

def main():
    st.set_page_config(layout="wide", page_title="TM2360E ìƒì‚° í’ˆì§ˆ ë¶„ì„ ëŒ€ì‹œë³´ë“œ")
    st.title("TM2360E ìƒì‚° í’ˆì§ˆ ë¶„ì„ ëŒ€ì‹œë³´ë“œ")
    st.markdown("---")
    
    # âœ… DB íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
    db_exists = os.path.exists(DB_FILE_NAME)
    
    if not db_exists:
        st.warning("âš ï¸ DB íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. CSV íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì—¬ DBë¥¼ ìƒì„±í•˜ì„¸ìš”.")
        st.info("ğŸ‘‰ ì•„ë˜ì—ì„œ CSV íŒŒì¼ì„ ì—…ë¡œë“œí•˜ë©´ ìë™ìœ¼ë¡œ DBê°€ ìƒì„±ë©ë‹ˆë‹¤.")
        
        # CSV ì—…ë¡œë“œ í™”ë©´ë§Œ í‘œì‹œ
        st.header("ğŸ“ CSV íŒŒì¼ ì—…ë¡œë“œ ë° DB ìƒì„±")
        
        uploaded_file = st.file_uploader(
            "CSV íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”",
            type=['csv'],
            help="TM2360E ê²€ì‚¬ ë°ì´í„° CSV íŒŒì¼ì„ ì—…ë¡œë“œí•˜ë©´ DBê°€ ìƒì„±ë©ë‹ˆë‹¤"
        )
        
        if uploaded_file is not None:
            try:
                df_uploaded = pd.read_csv(uploaded_file, encoding='utf-8', low_memory=False, dtype={'SNumber': str})
                
                st.success(f"âœ… íŒŒì¼ '{uploaded_file.name}' ì—…ë¡œë“œ ì„±ê³µ! (ì´ {len(df_uploaded):,}í–‰)")
                
                with st.expander("ğŸ“‹ ì—…ë¡œë“œëœ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° (ìƒìœ„ 100í–‰)", expanded=False):
                    st.dataframe(df_uploaded.head(100), use_container_width=True, height=400)
                
                if st.button("ğŸ’¾ DB ìƒì„± ë° ì €ì¥", type="primary", key='create_db_btn'):
                    with st.spinner("DBë¥¼ ìƒì„±í•˜ê³  ë°ì´í„°ë¥¼ ì €ì¥í•˜ëŠ” ì¤‘..."):
                        try:
                            # DB ìƒì„± ë° ì €ì¥
                            save_result = process_and_save_csv_to_db(df_uploaded, DB_FILE_NAME)
                            
                            if save_result['success']:
                                st.success("ğŸ‰ DBê°€ ìƒì„±ë˜ê³  ë°ì´í„°ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
                                st.info("í˜ì´ì§€ë¥¼ ìƒˆë¡œê³ ì¹¨í•˜ë©´ ì „ì²´ ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                                
                                st.markdown("### ğŸ“Š ì €ì¥ í†µê³„")
                                col1, col2, col3 = st.columns(3)
                                with col1:
                                    st.metric("T_MASTER_DATA", f"{save_result['stats'].get('master', 0):,}í–‰")
                                    st.metric("T_ITEM_PCB", f"{save_result['stats'].get('pcb', 0):,}í–‰")
                                    st.metric("T_ITEM_SEMI", f"{save_result['stats'].get('semi', 0):,}í–‰")
                                with col2:
                                    st.metric("T_ITEM_FW", f"{save_result['stats'].get('fw', 0):,}í–‰")
                                    st.metric("T_ITEM_RFTX", f"{save_result['stats'].get('rftx', 0):,}í–‰")
                                    st.metric("T_ITEM_BATADC", f"{save_result['stats'].get('batadc', 0):,}í–‰")
                                with col3:
                                    st.metric("T_PC_INFO", f"{save_result['stats'].get('pc_info', 0):,}í–‰")
                                    st.metric("T_SPEC_PCB", f"{save_result['stats'].get('spec_pcb', 0):,}í–‰")
                                    st.metric("T_SPEC_SEMI", f"{save_result['stats'].get('spec_semi', 0):,}í–‰")
                                
                                if st.button("ğŸ”„ ìƒˆë¡œê³ ì¹¨", type="secondary"):
                                    st.rerun()
                            else:
                                st.error(f"âŒ DB ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {save_result['error']}")
                        except Exception as e:
                            st.error(f"âŒ ì €ì¥ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")
                            import traceback
                            st.code(traceback.format_exc())
            except Exception as e:
                st.error(f"âŒ CSV íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}")
        
        st.stop()  # DBê°€ ì—†ìœ¼ë©´ ì—¬ê¸°ì„œ ì¤‘ë‹¨

    # --- 1. ì‚¬ì´ë“œë°”: ë©”ì¸ ì•¡ì…˜ ì„ íƒ ---
    with st.sidebar:
        st.header("âš™ï¸ ë¶„ì„ ë° DB ê´€ë¦¬")
        
        main_action = st.radio(
            "ìˆ˜í–‰í•  ì‘ì—…ì„ ì„ íƒí•˜ì„¸ìš”:",
            options=["DB ì¡°íšŒ ë° ë¶„ì„", "DB ì—…ë¡œë“œ ë° ì €ì¥", "DB ì‚­ì œ"],
            index=0, 
            key='main_action_selector'
        )
        st.markdown("---")
        
        # âœ… DB í…Œì´ë¸” ë¯¸ë¦¬ë³´ê¸° (ë¼ë””ì˜¤ë²„íŠ¼ ë°”ë¡œ ì•„ë˜)
        st.subheader("ğŸ” DB í…Œì´ë¸” ë¯¸ë¦¬ë³´ê¸°")
        
        preview_table = st.selectbox(
            "ì¡°íšŒí•  í…Œì´ë¸” ì„ íƒ",
            ['ì„ íƒí•˜ì„¸ìš”'] + DB_TABLES,
            key='preview_table_select'
        )
        
        preview_rows = st.number_input(
            "ì¡°íšŒ í–‰ ìˆ˜",
            min_value=10,
            max_value=910000,
            value=1000,
            step=1000,
            key='preview_rows_input'
        )
        
        if st.button("ğŸ“‹ í…Œì´ë¸” ë¯¸ë¦¬ë³´ê¸°", key='preview_btn'):
            if preview_table != 'ì„ íƒí•˜ì„¸ìš”':
                st.session_state['preview_executed'] = True
                st.session_state['preview_table_name'] = preview_table
                st.session_state['preview_rows_count'] = preview_rows
        
        st.markdown("---")
        
        # UI ìš”ì†Œ ë¡œë”© (ê³µí†µ)
        conn_ui = get_db_connection(DB_FILE_NAME)
        
        # ë‚ ì§œ/í’ˆëª© ì…ë ¥ í•„ë“œ
        default_start = datetime(2025, 10, 20).date()
        default_end = datetime(2025, 10, 25).date()
        start_date_ui = st.date_input("ğŸ—“ï¸ ì‹œì‘ ë‚ ì§œ (From)", default_start)
        end_date_ui = st.date_input("ğŸ—“ï¸ ì¢…ë£Œ ë‚ ì§œ (To)", default_end)
        item_ui = st.selectbox("í’ˆëª© ì„ íƒ", ITEM_OPTIONS, index=0, key='item_select')
        limit_ui = st.number_input("ì¡°íšŒ í–‰ ì œí•œ (Limit)", min_value=1000, value=100000, step=1000, key='limit_select')
        
        st.markdown("---")
        
        # âœ… í’ˆëª©ë³„ PC êµ¬ë¶„ ë™ì  ë³€ê²½
        st.subheader("ğŸ–¥ï¸ PC êµ¬ë¶„")
        
        pc_filter_options = ['ì „ì²´']
        try:
            if item_ui == 'pcb':
                # PCBëŠ” 100, 101, 102, 103
                df_pc_filtered = pd.read_sql(
                    "SELECT DISTINCT PC_ID FROM T_PC_INFO WHERE PC_Type = 'PCB' ORDER BY PC_ID",
                    conn_ui
                )
                if len(df_pc_filtered) > 0:
                    pc_filter_options.extend(df_pc_filtered['PC_ID'].tolist())
            elif item_ui == 'fw':
                # FW PC ëª©ë¡
                df_pc_filtered = pd.read_sql(
                    "SELECT DISTINCT PC_ID FROM T_PC_INFO WHERE PC_Type = 'FW' ORDER BY PC_ID",
                    conn_ui
                )
                if len(df_pc_filtered) > 0:
                    pc_filter_options.extend(df_pc_filtered['PC_ID'].tolist())
            elif item_ui == 'rftx':
                # RFTX PC ëª©ë¡
                df_pc_filtered = pd.read_sql(
                    "SELECT DISTINCT PC_ID FROM T_PC_INFO WHERE PC_Type = 'RFTX' ORDER BY PC_ID",
                    conn_ui
                )
                if len(df_pc_filtered) > 0:
                    pc_filter_options.extend(df_pc_filtered['PC_ID'].tolist())
            elif item_ui == 'batadc':
                # BATADC PC ëª©ë¡
                df_pc_filtered = pd.read_sql(
                    "SELECT DISTINCT PC_ID FROM T_PC_INFO WHERE PC_Type = 'BATADC' ORDER BY PC_ID",
                    conn_ui
                )
                if len(df_pc_filtered) > 0:
                    pc_filter_options.extend(df_pc_filtered['PC_ID'].tolist())
            # semiëŠ” PCê°€ ì—†ìœ¼ë¯€ë¡œ 'ì „ì²´'ë§Œ
        except Exception as e:
            st.warning(f"âš ï¸ PC ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        
        selected_pc_id = st.selectbox(
            f"{item_ui.upper()} PC ì„ íƒ",
            pc_filter_options,
            key='pc_filter_dynamic'
        )
        
        st.markdown("---")
        st.subheader("ğŸ“Š ìœ í˜• í•„í„°")
        
        # í’ˆëª©ë³„ ìœ í˜• ëª©ë¡ ì •ì˜
        measure_items_map = {
            'pcb': ['ì „ì²´', 'SleepCurr', 'BatVolt', 'IrCurr', 'IrPwr', 'WirelessVolt', 'UsbCurr', 'WirelessUsbVolt', 'Led'],
            'semi': ['ì „ì²´', 'BatVolt', 'SolarVolt'],
            'fw': ['ì „ì²´', 'FileCheck'],
            'rftx': ['ì „ì²´', 'Power', 'Modul', 'CFOD'],
            'batadc': ['ì „ì²´', 'Level', 'VoiceTh']
        }
        
        # ì„ íƒëœ í’ˆëª©ì— ë”°ë¥¸ ìœ í˜• ëª©ë¡ í‘œì‹œ
        available_items = measure_items_map.get(item_ui, ['ì „ì²´'])
        measure_item_filter = st.selectbox(
            "ì¸¡ì • ìœ í˜• ì„ íƒ",
            available_items,
            key='measure_item_filter'
        )
        
        st.markdown("---")
        
        # DB ì—°ê²° ë‹«ê¸°
        conn_ui.close()

    # --- 2. ë©”ì¸ í™”ë©´: ì„ íƒëœ ì•¡ì…˜ì— ë”°ë¥¸ UI ë Œë”ë§ ---
    
    if main_action == "DB ì¡°íšŒ ë° ë¶„ì„":
        
        # âœ… í…Œì´ë¸” ë¯¸ë¦¬ë³´ê¸° ê²°ê³¼ í‘œì‹œ (ìµœìƒë‹¨)
        if st.session_state.get('preview_executed', False):
            st.header("ğŸ“‹ DB í…Œì´ë¸” ë¯¸ë¦¬ë³´ê¸°")
            
            preview_table = st.session_state['preview_table_name']  # âœ… ë³€ê²½ëœ í‚¤
            preview_rows = st.session_state['preview_rows_count']  # âœ… ë³€ê²½ëœ í‚¤
            
            try:
                conn_preview = get_db_connection(DB_FILE_NAME)
                df_preview = pd.read_sql_query(f"SELECT * FROM {preview_table} LIMIT {preview_rows}", conn_preview)
                conn_preview.close()
                
                st.success(f"âœ… {preview_table} í…Œì´ë¸” | ì´ {len(df_preview):,}í–‰ ì¡°íšŒ")
                
                # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
                csv = df_preview.to_csv(index=False).encode('utf-8-sig')
                st.download_button(
                    label="ğŸ“¥ CSV ë‹¤ìš´ë¡œë“œ",
                    data=csv,
                    file_name=f"{preview_table}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                    mime="text/csv"
                )
                
                st.dataframe(df_preview, use_container_width=True, height=400)
                
                # ë¯¸ë¦¬ë³´ê¸° ë‹«ê¸° ë²„íŠ¼
                if st.button("âŒ ë¯¸ë¦¬ë³´ê¸° ë‹«ê¸°", key='close_preview'):
                    st.session_state['preview_executed'] = False
                    st.info("âœ… ë¯¸ë¦¬ë³´ê¸°ë¥¼ ë‹«ì•˜ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì‘ì—…ì„ ì§„í–‰í•˜ì„¸ìš”.")
                    
            except Exception as e:
                st.error(f"âŒ í…Œì´ë¸” ì¡°íšŒ ì˜¤ë¥˜: {e}")
            
            st.markdown("---")
        
        st.header("ğŸ“Š ê¸°ê°„ë³„ í’ˆì§ˆ ë¶„ì„ ê²°ê³¼")
        
        # âœ… ë¶„ì„ ì‹¤í–‰ ë²„íŠ¼
        if st.button("ğŸ” ë°ì´í„° ë¶„ì„ ì‹¤í–‰", key='run_analysis_btn', type="primary"):
            start_datetime = datetime(start_date_ui.year, start_date_ui.month, start_date_ui.day)
            end_datetime = datetime(end_date_ui.year, end_date_ui.month, end_date_ui.day)
            end_datetime_inclusive = end_datetime + timedelta(hours=23, minutes=59, seconds=59)
            
            if end_datetime < start_datetime:  # âœ… < ë¡œ ë³€ê²½ (ê°™ì€ ë‚ ì§œ í—ˆìš©)
                st.error("âš ï¸ ì¢…ë£Œ ë‚ ì§œëŠ” ì‹œì‘ ë‚ ì§œë³´ë‹¤ ì´ì „ì¼ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            else:
                # session_stateì— ë¶„ì„ ì‹¤í–‰ í”Œë˜ê·¸ ì„¤ì •
                st.session_state['analysis_executed'] = True
                st.session_state['analysis_params'] = {
                    'start': start_datetime,
                    'end': end_datetime_inclusive,
                    'item': item_ui,
                    'limit': limit_ui,
                    'pc_id': selected_pc_id,
                    'measure_item_filter': measure_item_filter
                }
        
        # âœ… ë¶„ì„ì´ ì‹¤í–‰ë˜ì—ˆìœ¼ë©´ ê²°ê³¼ë¥¼ ê³ ì •ëœ ì»¨í…Œì´ë„ˆì— í‘œì‹œ
        if st.session_state.get('analysis_executed', False):
            params = st.session_state['analysis_params']
            
            # ê³ ì •ëœ ì»¨í…Œì´ë„ˆì— ë¶„ì„ ê²°ê³¼ í‘œì‹œ
            analysis_container = st.container()
            with analysis_container:
                run_analysis(
                    params['start'], 
                    params['end'], 
                    params['item'], 
                    params['limit'], 
                    params['pc_id'],
                    params.get('measure_item_filter', 'ì „ì²´')
                )
        
        # âœ… ìƒì„¸ ì¡°íšŒ ì„¹ì…˜ (í•­ìƒ í‘œì‹œ)
        st.markdown("---")
        st.header("ğŸ” ë¶ˆëŸ‰ ìœ í˜•ë³„ SNumber ì¡°íšŒ")
        
        # íƒ­ìœ¼ë¡œ ë‘ ê°€ì§€ ì¡°íšŒ ë°©ë²• ì œê³µ
        tab1, tab2 = st.tabs(["ğŸ“Š ë¶ˆëŸ‰ ìœ í˜•ë³„ ì¡°íšŒ", "ğŸ” SNumber ì§ì ‘ ê²€ìƒ‰"])
     
        with tab1:
            st.markdown("### ë¶ˆëŸ‰ ë¶„ë¥˜ë³„ SNumber ëª©ë¡ ì¡°íšŒ")
            st.info("ğŸ’¡ ë¨¼ì € ë°ì´í„° ë¶„ì„ì„ ì‹¤í–‰í•œ í›„ì— ì´ ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ì„¸ìš”!")
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                category_1st = st.selectbox(
                    "1ì°¨ ë¶„ë¥˜ ì„ íƒ",
                    ["Pass", "ê°€ì„±ë¶ˆëŸ‰", "ì§„ì„±ë¶ˆëŸ‰"],
                    key="category_1st_select"
                )
            
            with col2:
                category_2nd = st.selectbox(
                    "2ì°¨ ë¶„ë¥˜ ì„ íƒ",
                    ["Pass", "ë¯¸ë‹¬", "ì´ˆê³¼", "ì œì™¸"],
                    key="category_2nd_select"
                )
            
            with col3:
                st.write("")  # ê°„ê²© ì¡°ì •
                st.write("")  # ê°„ê²© ì¡°ì •
                query_by_category_btn = st.button(
                    "ğŸ” ì¡°íšŒ", 
                    key="query_by_category_btn",
                    type="primary"
                )
            
            # ë¶ˆëŸ‰ ìœ í˜•ë³„ ì¡°íšŒ ì‹¤í–‰
            if query_by_category_btn:
                if not st.session_state.get('analysis_executed', False):
                    st.warning("âš ï¸ ë¨¼ì € 'ë°ì´í„° ë¶„ì„ ì‹¤í–‰' ë²„íŠ¼ì„ ëˆŒëŸ¬ ë°ì´í„°ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”!")
                else:
                    # session_stateì— ë¶ˆëŸ‰ ì¡°íšŒ ì •ë³´ ì €ì¥
                    st.session_state['defect_query_executed'] = True
                    st.session_state['defect_category_1st'] = category_1st
                    st.session_state['defect_category_2nd'] = category_2nd
            
            # ë¶ˆëŸ‰ ì¡°íšŒ ê²°ê³¼ í‘œì‹œ
            defect_query_container = st.container()
            with defect_query_container:
                if st.session_state.get('defect_query_executed', False):
                    show_snumbers_by_defect_type(
                        st.session_state['defect_category_1st'],
                        st.session_state['defect_category_2nd'],
                        st.session_state['analysis_params']
                    )
        
        with tab2:
            st.markdown("### SNumber ì§ì ‘ ê²€ìƒ‰")
            st.markdown("""
            **ğŸ’¡ ê²€ìƒ‰ íŒ:**
            - ì „ì²´ SNumber ì…ë ¥: `THSRBN5901480USMJNYAH9226`
            - ì¼ë¶€ë§Œ ì…ë ¥: `THSR`, `9226`, `BN590`
            - ì™€ì¼ë“œì¹´ë“œ ì‚¬ìš©: `THSR*`, `*9226`, `*BN590*`
            """)
            
            snumber_input_main = st.text_input(
                "ì¡°íšŒí•  SNumber ì…ë ¥ (ì¼ë¶€ë§Œ ì…ë ¥í•´ë„ ìë™ ê²€ìƒ‰)", 
                value="", 
                placeholder="ì˜ˆ: THSR, *9226, THSRBN590*",
                key="snumber_input_main"
            )
            
            col1, col2 = st.columns([1, 4])
            with col1:
                search_clicked = st.button("ğŸ” ê²€ìƒ‰ ë° ìƒì„¸ ì¡°íšŒ", key="detail_query_btn_main", type="secondary")
            
            # ê²€ìƒ‰/ìƒì„¸ ì¡°íšŒ ì„¹ì…˜ (ë…ë¦½ëœ ì»¨í…Œì´ë„ˆ)
            detail_container = st.container()
            
            with detail_container:
                if search_clicked:
                    if snumber_input_main:
                        # session_stateì— ê²€ìƒ‰ ì‹¤í–‰ í”Œë˜ê·¸ ì„¤ì •
                        st.session_state['search_executed'] = True
                        st.session_state['search_query'] = snumber_input_main
                    else:
                        st.warning("âš ï¸ SNumberë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                
                # ê²€ìƒ‰ì´ ì‹¤í–‰ë˜ì—ˆìœ¼ë©´ ê²°ê³¼ í‘œì‹œ
                if st.session_state.get('search_executed', False):
                    show_snumber_detail(st.session_state['search_query'], item_ui)

    elif main_action == "DB ì—…ë¡œë“œ ë° ì €ì¥":
        st.header("ğŸ“ CSV íŒŒì¼ ì—…ë¡œë“œ ë° DB ëˆ„ì  ì €ì¥")
        
        st.info("""
        ğŸ’¡ **ì‚¬ìš© ë°©ë²•:**
        1. CSV íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”
        2. ì—…ë¡œë“œëœ íŒŒì¼ ì •ë³´ë¥¼ í™•ì¸í•˜ì„¸ìš”
        3. "DBì— ì €ì¥" ë²„íŠ¼ì„ í´ë¦­í•˜ë©´ ë°ì´í„°ê°€ DBì— ì¶”ê°€ë©ë‹ˆë‹¤
        4. ì €ì¥ ì™„ë£Œ í›„ DB íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
        """)
        
        st.markdown("---")
        
        # CSV íŒŒì¼ ì—…ë¡œë“œ
        uploaded_file = st.file_uploader(
            "CSV íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”",
            type=['csv'],
            help="TM2360E ê²€ì‚¬ ë°ì´í„° CSV íŒŒì¼ë§Œ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤"
        )
        
        if uploaded_file is not None:
            try:
                # CSV íŒŒì¼ ì½ê¸°
                df_uploaded = pd.read_csv(uploaded_file, encoding='utf-8', low_memory=False, dtype={'SNumber': str})
                
                st.success(f"âœ… íŒŒì¼ '{uploaded_file.name}' ì—…ë¡œë“œ ì„±ê³µ! (ì´ {len(df_uploaded):,}í–‰)")
                
                # ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°
                with st.expander("ğŸ“‹ ì—…ë¡œë“œëœ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° (ìƒìœ„ 100í–‰)", expanded=False):
                    st.dataframe(df_uploaded.head(100), use_container_width=True, height=400)
                
                # ì»¬ëŸ¼ ì •ë³´
                with st.expander("ğŸ“Š ì»¬ëŸ¼ ì •ë³´", expanded=False):
                    col_info = pd.DataFrame({
                        'ì»¬ëŸ¼ëª…': df_uploaded.columns,
                        'ë°ì´í„° íƒ€ì…': df_uploaded.dtypes.astype(str).values,  # âœ… Arrow ì—ëŸ¬ ë°©ì§€
                        'NULL ê°œìˆ˜': df_uploaded.isnull().sum().values,
                        'ê³ ìœ ê°’ ê°œìˆ˜': [df_uploaded[col].nunique() for col in df_uploaded.columns]
                    })
                    st.dataframe(col_info, use_container_width=True)
                
                st.markdown("---")
                
                # DB ì €ì¥ ë²„íŠ¼
                if st.button("ğŸ’¾ DBì— ì €ì¥ (APPEND ëª¨ë“œ)", type="primary", key='save_to_db_btn'):
                    with st.spinner("ë°ì´í„°ë¥¼ DBì— ì €ì¥í•˜ëŠ” ì¤‘..."):
                        try:
                            # DB ì €ì¥ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰
                            save_result = process_and_save_csv_to_db(df_uploaded, DB_FILE_NAME)
                            
                            if save_result['success']:
                                st.success("ğŸ‰ ë°ì´í„°ê°€ ì„±ê³µì ìœ¼ë¡œ DBì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
                                
                                # ì €ì¥ í†µê³„ í‘œì‹œ
                                st.markdown("### ğŸ“Š ì €ì¥ í†µê³„")
                                
                                col1, col2, col3 = st.columns(3)
                                with col1:
                                    st.metric("T_MASTER_DATA", f"{save_result['stats'].get('master', 0):,}í–‰")
                                    st.metric("T_ITEM_PCB", f"{save_result['stats'].get('pcb', 0):,}í–‰")
                                    st.metric("T_ITEM_SEMI", f"{save_result['stats'].get('semi', 0):,}í–‰")
                                with col2:
                                    st.metric("T_ITEM_FW", f"{save_result['stats'].get('fw', 0):,}í–‰")
                                    st.metric("T_ITEM_RFTX", f"{save_result['stats'].get('rftx', 0):,}í–‰")
                                    st.metric("T_ITEM_BATADC", f"{save_result['stats'].get('batadc', 0):,}í–‰")
                                with col3:
                                    st.metric("T_PC_INFO", f"{save_result['stats'].get('pc_info', 0):,}í–‰")
                                    st.metric("T_SPEC_PCB", f"{save_result['stats'].get('spec_pcb', 0):,}í–‰")
                                    st.metric("T_SPEC_SEMI", f"{save_result['stats'].get('spec_semi', 0):,}í–‰")
                                
                                # ë¡œê·¸ í‘œì‹œ
                                with st.expander("ğŸ“ ì €ì¥ ë¡œê·¸ ë³´ê¸°", expanded=False):
                                    st.code(save_result['log'])
                                    
                            else:
                                st.error(f"âŒ DB ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {save_result['error']}")
                                
                        except Exception as e:
                            st.error(f"âŒ ì €ì¥ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")
                            import traceback
                            st.code(traceback.format_exc())
            
            except Exception as e:
                st.error(f"âŒ CSV íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}")
        
        st.markdown("---")
        
        # DB ë‹¤ìš´ë¡œë“œ ì„¹ì…˜
        st.header("ğŸ“¥ DB íŒŒì¼ ë‹¤ìš´ë¡œë“œ")
        
        if os.path.exists(DB_FILE_NAME):
            file_size = os.path.getsize(DB_FILE_NAME) / (1024 * 1024)  # MB
            st.info(f"í˜„ì¬ DB íŒŒì¼ í¬ê¸°: **{file_size:.2f} MB**")
            
            with open(DB_FILE_NAME, 'rb') as f:
                db_data = f.read()
            
            download_filename = f"product_quality_db_{datetime.now().strftime('%Y%m%d_%H%M%S')}.db"
            
            st.download_button(
                label="ğŸ’¾ DB íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
                data=db_data,
                file_name=download_filename,
                mime="application/x-sqlite3",
                help="í˜„ì¬ DB íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤"
            )
        else:
            st.warning("âš ï¸ DB íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
    
    elif main_action == "DB ì‚­ì œ":
        st.header("ğŸ—‘ï¸ DB ë°ì´í„° ì‚­ì œ (ì£¼ì°¨ë³„)")
        
        st.warning("""
        âš ï¸ **ì£¼ì˜:**
        - ì„ íƒí•œ ì£¼ì°¨(WEEK_NO)ì˜ ë°ì´í„°ë§Œ ì‚­ì œë©ë‹ˆë‹¤
        - DB íŒŒì¼ê³¼ ìŠ¤í‚¤ë§ˆëŠ” ìœ ì§€ë©ë‹ˆë‹¤
        - ì‚­ì œëœ ë°ì´í„°ëŠ” ë³µêµ¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤
        """)
        
        st.markdown("---")
        
        # DBì—ì„œ WEEK_NO ëª©ë¡ ì¡°íšŒ
        try:
            conn_delete = get_db_connection(DB_FILE_NAME)
            df_weeks = pd.read_sql("SELECT DISTINCT WEEK_NO FROM T_MASTER_DATA WHERE WEEK_NO IS NOT NULL ORDER BY WEEK_NO DESC", conn_delete)
            week_list = df_weeks['WEEK_NO'].tolist()
            
            if len(week_list) == 0:
                st.info("â„¹ï¸ ì‚­ì œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. (WEEK_NOê°€ ì—†ìŒ)")
                conn_delete.close()
            else:
                # ì£¼ì°¨ë³„ ë°ì´í„° í†µê³„
                st.subheader("ğŸ“Š ì£¼ì°¨ë³„ ë°ì´í„° í˜„í™©")
                
                week_stats = []
                for week in week_list:
                    master_count = pd.read_sql(f"SELECT COUNT(*) as cnt FROM T_MASTER_DATA WHERE WEEK_NO = '{week}'", conn_delete)['cnt'][0]
                    pcb_count = pd.read_sql(f"SELECT COUNT(*) as cnt FROM T_ITEM_PCB WHERE SNumber IN (SELECT SNumber FROM T_MASTER_DATA WHERE WEEK_NO = '{week}')", conn_delete)['cnt'][0]
                    semi_count = pd.read_sql(f"SELECT COUNT(*) as cnt FROM T_ITEM_SEMI WHERE SNumber IN (SELECT SNumber FROM T_MASTER_DATA WHERE WEEK_NO = '{week}')", conn_delete)['cnt'][0]
                    
                    week_stats.append({
                        'WEEK_NO': week,
                        'MASTER': f"{master_count:,}",
                        'PCB': f"{pcb_count:,}",
                        'SEMI': f"{semi_count:,}"
                    })
                
                df_stats = pd.DataFrame(week_stats)
                st.dataframe(df_stats, use_container_width=True, hide_index=True)
                
                conn_delete.close()
                
                st.markdown("---")
                
                # ì‚­ì œí•  ì£¼ì°¨ ì„ íƒ
                st.subheader("ğŸ—‘ï¸ ì‚­ì œí•  ì£¼ì°¨ ì„ íƒ")
                
                selected_weeks = st.multiselect(
                    "ì‚­ì œí•  WEEK_NOë¥¼ ì„ íƒí•˜ì„¸ìš” (ë³µìˆ˜ ì„ íƒ ê°€ëŠ¥)",
                    week_list,
                    help="ì—¬ëŸ¬ ì£¼ì°¨ë¥¼ ì„ íƒí•˜ì—¬ í•œ ë²ˆì— ì‚­ì œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤"
                )
                
                if selected_weeks:
                    st.warning(f"âš ï¸ ì„ íƒëœ ì£¼ì°¨: {', '.join(selected_weeks)}")
                    
                    # ì‚­ì œë  ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°
                    conn_preview = get_db_connection(DB_FILE_NAME)
                    week_filter = "', '".join(selected_weeks)
                    
                    delete_master = pd.read_sql(f"SELECT COUNT(*) as cnt FROM T_MASTER_DATA WHERE WEEK_NO IN ('{week_filter}')", conn_preview)['cnt'][0]
                    delete_pcb = pd.read_sql(f"SELECT COUNT(*) as cnt FROM T_ITEM_PCB WHERE SNumber IN (SELECT SNumber FROM T_MASTER_DATA WHERE WEEK_NO IN ('{week_filter}'))", conn_preview)['cnt'][0]
                    delete_semi = pd.read_sql(f"SELECT COUNT(*) as cnt FROM T_ITEM_SEMI WHERE SNumber IN (SELECT SNumber FROM T_MASTER_DATA WHERE WEEK_NO IN ('{week_filter}'))", conn_preview)['cnt'][0]
                    
                    conn_preview.close()
                    
                    st.info(f"""
                    ğŸ“Š **ì‚­ì œë  ë°ì´í„°:**
                    - T_MASTER_DATA: {delete_master:,}í–‰
                    - T_ITEM_PCB: {delete_pcb:,}í–‰
                    - T_ITEM_SEMI: {delete_semi:,}í–‰
                    - T_ITEM_FW, T_ITEM_RFTX, T_ITEM_BATADC: ê´€ë ¨ ë°ì´í„°
                    """)
                    
                    # í™•ì¸ ì²´í¬ë°•ìŠ¤
                    confirm_delete = st.checkbox(f"ìœ„ ë‚´ìš©ì„ í™•ì¸í–ˆìœ¼ë©°, ì„ íƒí•œ ì£¼ì°¨({', '.join(selected_weeks)})ì˜ ë°ì´í„°ë¥¼ ì‚­ì œí•˜ê² ìŠµë‹ˆë‹¤")
                    
                    if confirm_delete:
                        if st.button("ğŸ—‘ï¸ ì„ íƒí•œ ì£¼ì°¨ ë°ì´í„° ì‚­ì œ", type="secondary"):
                            try:
                                conn_del = get_db_connection(DB_FILE_NAME)
                                cursor = conn_del.cursor()
                                
                                # FOREIGN KEY ì œì•½ì¡°ê±´ ì„ì‹œ ë¹„í™œì„±í™”
                                cursor.execute("PRAGMA foreign_keys = OFF;")
                                
                                week_filter = "', '".join(selected_weeks)
                                
                                # SNumber ëª©ë¡ ì¶”ì¶œ
                                snumber_query = f"SELECT SNumber FROM T_MASTER_DATA WHERE WEEK_NO IN ('{week_filter}')"
                                df_snumbers = pd.read_sql(snumber_query, conn_del)
                                snumber_list = df_snumbers['SNumber'].tolist()
                                
                                if len(snumber_list) > 0:
                                    snumber_filter = "', '".join(snumber_list)
                                    
                                    # ê´€ë ¨ í…Œì´ë¸” ì‚­ì œ
                                    cursor.execute(f"DELETE FROM T_ITEM_PCB WHERE SNumber IN ('{snumber_filter}')")
                                    cursor.execute(f"DELETE FROM T_ITEM_SEMI WHERE SNumber IN ('{snumber_filter}')")
                                    cursor.execute(f"DELETE FROM T_ITEM_FW WHERE SNumber IN ('{snumber_filter}')")
                                    cursor.execute(f"DELETE FROM T_ITEM_RFTX WHERE SNumber IN ('{snumber_filter}')")
                                    cursor.execute(f"DELETE FROM T_ITEM_BATADC WHERE SNumber IN ('{snumber_filter}')")
                                    
                                    # ë§ˆìŠ¤í„° ë°ì´í„° ì‚­ì œ
                                    cursor.execute(f"DELETE FROM T_MASTER_DATA WHERE WEEK_NO IN ('{week_filter}')")
                                
                                # FOREIGN KEY ì œì•½ì¡°ê±´ ë‹¤ì‹œ í™œì„±í™”
                                cursor.execute("PRAGMA foreign_keys = ON;")
                                
                                conn_del.commit()
                                conn_del.close()
                                
                                st.success(f"âœ… ì„ íƒí•œ ì£¼ì°¨({', '.join(selected_weeks)})ì˜ ë°ì´í„°ê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.")
                                st.info("í˜ì´ì§€ë¥¼ ìƒˆë¡œê³ ì¹¨í•˜ì„¸ìš”.")
                                
                                if st.button("ğŸ”„ ìƒˆë¡œê³ ì¹¨"):
                                    st.rerun()
                                    
                            except Exception as e:
                                st.error(f"âŒ ë°ì´í„° ì‚­ì œ ì‹¤íŒ¨: {e}")
                                import traceback
                                st.code(traceback.format_exc())
                
        except Exception as e:
            st.error(f"âŒ WEEK_NO ì¡°íšŒ ì‹¤íŒ¨: {e}")


if __name__ == "__main__":
    main()
